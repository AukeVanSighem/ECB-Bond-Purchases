{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:57:17.168758Z",
     "start_time": "2021-05-11T15:57:04.849150Z"
    }
   },
   "outputs": [],
   "source": [
    "# List of modules that are not installed in the course\n",
    "!pip install OpenPermID\n",
    "!pip install Levenshtein\n",
    "!pip install geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:57:20.224156Z",
     "start_time": "2021-05-11T15:57:17.171751Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Downloading all bonds ever owned in CSPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:57:20.365425Z",
     "start_time": "2021-05-11T15:57:20.227101Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import requests, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:57:20.381371Z",
     "start_time": "2021-05-11T15:57:20.367394Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This function gets the csv from the url and places the new data in a dictionary with keys = ISIN,\n",
    "# and value = [NCB, ISSUER, MATURITY DATE, COUPON RATE]\n",
    "def downloadDataToDictionary(url,dictionary):\n",
    "    r = requests.get(url) # create HTTP response object\n",
    "    nameCompany = '' # make a string for the company name \n",
    "                     # (do this here so that is in scope of whole function)\n",
    "    if r.status_code != 200: return # if website wasn't accessed in the right way, \n",
    "                                    # stop the function\n",
    "    # this for loop loops through all the lines of the retrieved csv-file, except for the heading\n",
    "    for line in r.text.split('\\r\\n')[1:]:\n",
    "        if not re.search(r'[a-z]',line): continue # if the line doesn't contain letters, \n",
    "                                                  # go to the next line\n",
    "        if re.search(r',+$',line): line = re.sub(r',+$',r'',line) # remove commas at end of line\n",
    "        splitLine = line.split(',')\n",
    "        if len(splitLine) < 5: continue # We expect at least 5 items as we want 5 columns \n",
    "                                        # and name could lead to additional columns\n",
    "        if re.search(r'(?:\\\".*,.*\\\")',line): # searches commas between \" as these are part of the name \n",
    "                                             # and shouldn't be split\n",
    "            nameCompany = re.search(r'(?:\\\".*,.*\\\")',line).group(0) \n",
    "                                             # name of the company is between the \"\"\n",
    "            nameCompany = re.sub(r\"\\\"\",\"\",nameCompany) # remove the \"\"\n",
    "        else:\n",
    "            for str in splitLine:\n",
    "                re.sub('\\\"','',str)\n",
    "            nameCompany = splitLine[2]\n",
    "        if (splitLine[1] not in dictionary): # only add new ISINs to the dictionary\n",
    "            dictionary[splitLine[1]] = [splitLine[0], nameCompany, splitLine[-2], splitLine[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:57:53.173039Z",
     "start_time": "2021-05-11T15:57:20.384345Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dateToDownload = datetime.date(2017, 6, 23)\n",
    "change_url_date = datetime.date(2020, 3, 27)\n",
    "end_date = datetime.date(2021,4,23)\n",
    "delta = datetime.timedelta(days=7)\n",
    "dictionaryBondsECB = {}\n",
    "\n",
    "while dateToDownload <= change_url_date:\n",
    "    date = dateToDownload.strftime(\"%Y%m%d\")\n",
    "    url = \"https://www.ecb.europa.eu/mopo/pdf/CSPPholdings_\"+date+\".csv\"\n",
    "    downloadDataToDictionary(url,dictionaryBondsECB)\n",
    "    dateToDownload += delta\n",
    "dateToDownload+delta\n",
    "while dateToDownload <= end_date:\n",
    "    date = dateToDownload.strftime(\"%Y%m%d\")\n",
    "    url = \"https://www.ecb.europa.eu/mopo/pdf/CSPP_PEPP_corporate_bond_holdings_\"+date+\".csv\"\n",
    "    downloadDataToDictionary(url,dictionaryBondsECB)\n",
    "    dateToDownload += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:57:53.204952Z",
     "start_time": "2021-05-11T15:57:53.175034Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matrixData = [] # 2D array with row per ISIN and columns for different data\n",
    "for ISIN, dataInDictionary in dictionaryBondsECB.items():\n",
    "    item = [ISIN] + dataInDictionary\n",
    "    matrixData.append(item)\n",
    "holdingsECB = pd.DataFrame(matrixData, columns=[\"ISIN\",\"NCB\",\"ISSUER\",\"MATURITY DATE\",\"COUPON RATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:57:53.236867Z",
     "start_time": "2021-05-11T15:57:53.209941Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Export data to csv for easy retrieval on computers with Eikon\n",
    "holdingsECB.to_csv('data/holdingsECB.csv',index=False,sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ECB green bonds that are listed on Euronext stock exchange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:57:53.755115Z",
     "start_time": "2021-05-11T15:57:53.240858Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#reading data of green bonds listed on Euronext \n",
    "euronext_greenbonds = pd.read_excel(\"data/Euronext-Green-Bond-List.xlsx\", header=0)\n",
    "euronext_greenbonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:57:53.770076Z",
     "start_time": "2021-05-11T15:57:53.757111Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Getting the ISIN of the Euronext green bonds \n",
    "euronext_greenbond_isin = euronext_greenbonds[\"ISIN\"]\n",
    "euronext_greenbond_isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:57:53.800993Z",
     "start_time": "2021-05-11T15:57:53.772071Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Comparing the ISINs of the ECB and Euronext green bonds and returning matches \n",
    "ecbgreenbonds = holdingsECB[(holdingsECB[\"ISIN\"].isin(euronext_greenbond_isin))]\n",
    "ecbgreenbonds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Sector Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all sector data from PermID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:57:53.973068Z",
     "start_time": "2021-05-11T15:57:53.803986Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Requirements\n",
    "from OpenPermID import OpenPermID\n",
    "import Levenshtein\n",
    "import geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:57:53.989027Z",
     "start_time": "2021-05-11T15:57:53.975102Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Gain access to the permid database\n",
    "opid = OpenPermID()\n",
    "opid.set_access_token(\"r95vEAhvmucG8iNGtsP17hjbgUGMhz4j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:01:40.003219Z",
     "start_time": "2021-05-11T15:57:53.991022Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "holdingsECB = pd.read_csv(\"data/holdingsECB.csv\", header=0, delimiter=';')\n",
    "companies = holdingsECB.ISSUER.astype('string').unique()\n",
    "permid_mappings = pd.DataFrame({})\n",
    "unmapped_companies = []\n",
    "\n",
    "for company in companies:\n",
    "    \n",
    "    # In case of connection error, allow it to try at most 5 times\n",
    "    err, count = 0, 0\n",
    "    while (err != None and count < 5):\n",
    "        output, err = opid.search(company)\n",
    "        count = count - 1\n",
    "    if err != None:\n",
    "        unmapped_companies.append(company)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    df = output['organizations']\n",
    "    if len(df) == 0:\n",
    "        permid = np.NaN\n",
    "        name = np.NaN\n",
    "    elif len(df) == 1:\n",
    "        permid = df.iloc[0,0].split('/')[-1]\n",
    "        name = df.iloc[0,1]\n",
    "    else:\n",
    "        # If multiple records are return, choose the record which the company name is the most similar to the keyword\n",
    "        similarityScores = df.organizationName.apply(lambda x: Levenshtein.ratio(company, x))\n",
    "        max_index = similarityScores.idxmax()\n",
    "        permid = df.iloc[max_index, 0].split('/')[-1]\n",
    "        name = df.iloc[max_index, 1]\n",
    "    permid_mappings = permid_mappings.append(pd.DataFrame({'keyword':[company], 'companyName': [name], 'PermID':[permid]}))\n",
    "    \n",
    "permid_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:21.418648Z",
     "start_time": "2021-05-11T16:01:40.005175Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "permids = permid_mappings.PermID.dropna().astype('string')\n",
    "sector_lookups = pd.DataFrame({})\n",
    "unsuccessful_lookups = []\n",
    "\n",
    "for permid in permids:\n",
    "    \n",
    "    # In case of connection error, allow it to try at most 5 times\n",
    "    err, count = 0, 0\n",
    "    while (err != None and count < 5):\n",
    "        output, err = opid.lookup(permid)\n",
    "        count = count - 1\n",
    "    if err != None:\n",
    "        unsuccessful_lookups.append(permid)\n",
    "        continue\n",
    "\n",
    "    if \"hasPrimaryBusinessSector\" in output.columns:\n",
    "        sector_info = output.loc[:, 'hasPrimaryBusinessSector': 'hasPrimaryIndustryGroup']\n",
    "        sector_info = sector_info.applymap(lambda x: x.split('/')[-1])\n",
    "    if \"isIncorporatedIn\" in output.columns:\n",
    "        loc_info = output.loc[:, 'isIncorporatedIn': 'isDomiciledIn']\n",
    "        loc_info = loc_info.applymap(lambda x: x.split('/')[-2])\n",
    "        \n",
    "    row = pd.DataFrame({'PermID': [permid]})\n",
    "    row = pd.concat([row, sector_info], axis = 1) if type(sector_info) == pd.DataFrame else row\n",
    "    row = pd.concat([row, loc_info], axis = 1) if type(loc_info) == pd.DataFrame else row\n",
    "    sector_lookups = sector_lookups.append(row)\n",
    "    \n",
    "    sector_info, loc_info = None, None\n",
    "\n",
    "sector_lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:36.292296Z",
     "start_time": "2021-05-11T16:02:21.420643Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sector_lookups_converted = sector_lookups.copy()\n",
    "sector_types = sector_lookups.columns[1:4]\n",
    "for sector_type in sector_types:\n",
    "    sector_dict = {}\n",
    "    sectors = sector_lookups.loc[:, sector_type].dropna().astype('string').unique()\n",
    "    for sector in sectors:\n",
    "        output, err = opid.lookup(sector)\n",
    "        sector_dict[sector] = output.iloc[0, -1]\n",
    "    sector_lookups_converted[sector_type] = sector_lookups[sector_type].fillna('missing').astype('string').apply(lambda x: np.NaN if x == 'missing' else sector_dict[x])\n",
    "\n",
    "loc_types = sector_lookups.columns[4:]\n",
    "for loc_type in loc_types:\n",
    "    loc_dict = {}\n",
    "    locs = sector_lookups.loc[:, loc_type].dropna().astype('string').unique()\n",
    "    for loc in locs:\n",
    "        g = geocoder.geonames(loc, method='details', key='brian1998716')\n",
    "        loc_dict[loc] = g.address\n",
    "    sector_lookups_converted[loc_type] = sector_lookups[loc_type].fillna('missing').astype('string').apply(lambda x: np.NaN if x == 'missing' else loc_dict[x])\n",
    "\n",
    "sector_lookups_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:36.324190Z",
     "start_time": "2021-05-11T16:02:36.293271Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sector_mappings = pd.merge(permid_mappings, sector_lookups_converted, how = 'left', on = 'PermID')\n",
    "sector_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:36.339151Z",
     "start_time": "2021-05-11T16:02:36.325188Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sector_mappings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Represent industries and sectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pie chart to represent the number of times an industry, sector or supersector is present in the data (multiple bonds for the same company are counted separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:36.355108Z",
     "start_time": "2021-05-11T16:02:36.341146Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # TODO: add to requirements if used\n",
    "\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        if (pct > 2.4):\n",
    "            return '{p:.2f}%'.format(p=pct)\n",
    "        else:\n",
    "            return ''\n",
    "    return my_autopct\n",
    "\n",
    "def get_all_sectors(sector_type):\n",
    "    sector_mappings['number']=1 # TODO: count them in a cleaner way\n",
    "    sectors = sector_mappings[[sector_type, 'number']].groupby([sector_type]).sum()\n",
    "    sectors = sectors.sort_values(\"number\", axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)\n",
    "    return sectors\n",
    "    \n",
    "def make_pie_chart(column_name):\n",
    "    fig = plt.figure(figsize=(9,9))\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    sectors = get_all_sectors(column_name)\n",
    "    \n",
    "    sectors.plot(kind='pie', y='number', ax=ax, autopct=make_autopct(sectors['number']), fontsize=12, legend=False, rotatelabels=True, pctdistance=0.8)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(column_name+\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:36.939436Z",
     "start_time": "2021-05-11T16:02:36.360097Z"
    }
   },
   "outputs": [],
   "source": [
    "make_pie_chart('hasPrimaryBusinessSector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:37.160797Z",
     "start_time": "2021-05-11T16:02:36.940387Z"
    }
   },
   "outputs": [],
   "source": [
    "make_pie_chart('hasPrimaryEconomicSector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:37.176755Z",
     "start_time": "2021-05-11T16:02:37.161795Z"
    }
   },
   "outputs": [],
   "source": [
    "# make_pie_chart('hasPrimaryIndustryGroup') # TODO: fix error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which industries and sectors are green?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:15:46.452282Z",
     "start_time": "2021-05-11T16:15:46.152686Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data from kaggle: https://www.kaggle.com/cathetorres/ghg-emissions-by-country-and-economic-sector\n",
    "historical_emissions = pd.read_csv(\"data/Sector_data/historical_emissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:15:47.776936Z",
     "start_time": "2021-05-11T16:15:47.762976Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter out all the sectors from the EU for which kaggle has emission data\n",
    "historical_emissions_EU = historical_emissions[historical_emissions[\"Country\"]== \"European Union (27)\"]\n",
    "\n",
    "def get_all_sectors_EU(sector_type): #TODO: make function one with previous\n",
    "    historical_emissions_EU[\"number\"]=1 # TODO: count them in a cleaner way\n",
    "    sectors_EU = historical_emissions_EU[[sector_type, \"number\"]].groupby([sector_type]).sum()\n",
    "    sectors_EU = sectors_EU.sort_values(\"number\", axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)\n",
    "    return sectors_EU\n",
    "\n",
    "get_all_sectors_EU(\"Sector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: map these sectors with the ones in which ECB invested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: analyse the emission known for every sector and decide on a threshold to call some of them green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: find a way to calculate which percentage is green and conlude whether this is more than random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all the Eikon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:37.334240Z",
     "start_time": "2021-05-11T16:02:37.194708Z"
    }
   },
   "outputs": [],
   "source": [
    "eikon_data_folder = \"data/\"\n",
    "eikon_data_environment = pd.read_csv(eikon_data_folder+\"holdingsECBEnvironment.txt\",sep=\"\\t\")\n",
    "# TODO: remove right, empty columns from data frame\n",
    "eikon_data_general = pd.read_csv(eikon_data_folder+\"holdingsECBGeneralInfo.txt\",sep=\"\\t\")\n",
    "eikon_data_industry = pd.read_csv(eikon_data_folder+\"holdingsECBIndustryAndSector.txt\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:37.365191Z",
     "start_time": "2021-05-11T16:02:37.337234Z"
    }
   },
   "outputs": [],
   "source": [
    "eikon_data_merged = eikon_data_general.merge(eikon_data_environment, \"left\", \"ISIN\") #append environment\n",
    "eikon_data_complete = eikon_data_merged.merge(eikon_data_industry, \"left\", \"ISIN\") # appended industry\n",
    "eikon_data_complete.rename(columns={'CO2.1': 'CO2_1'}, inplace=True) #changed column name to prevent syntax errors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read all data from eligible universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:37.428987Z",
     "start_time": "2021-05-11T16:02:37.368167Z"
    }
   },
   "outputs": [],
   "source": [
    "eligible_environment = pd.read_csv(eikon_data_folder+\"eligibleUniverseEnvironment.txt\",sep=\"\\t\")\n",
    "eligible_general = pd.read_csv(eikon_data_folder+\"eligibleUniverseGeneralInfo.txt\",sep=\"\\t\")\n",
    "eligible_industry = pd.read_csv(eikon_data_folder+\"eligibleUniverseIndustryAndSector.txt\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:37.444943Z",
     "start_time": "2021-05-11T16:02:37.429985Z"
    }
   },
   "outputs": [],
   "source": [
    "eligible_complete = eligible_general.merge(eligible_environment, \"left\", \"ISIN\").merge(eligible_industry, \"left\", \"ISIN\")\n",
    "eligible_complete.rename(columns={\"Issuer\": \"ISSUER\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare how many bonds from the eligible universe the ECB bought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:37.460904Z",
     "start_time": "2021-05-11T16:02:37.446939Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overlap = eikon_data_complete[(eikon_data_complete[\"ISIN\"].isin(eligible_complete[\"ISIN\"]))]\n",
    "print(\"the percentage of bonds bought by ECB in eligible universe that we have info on:    \", \n",
    "      overlap.shape[0]/eligible_complete.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Eikon and PermID databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:38.328608Z",
     "start_time": "2021-05-11T16:02:37.462898Z"
    }
   },
   "outputs": [],
   "source": [
    "NaN_message = \"Unable to collect data for the field(.*)\"\n",
    "sector_data = eikon_data_complete[['ISIN', 'NCB', 'ISSUER','ICB Industry name','ICB Sector name','ICB Supersector name']]\n",
    "sector_data = sector_data.replace(to_replace = NaN_message, value = np.NaN, regex = True)\n",
    "\n",
    "sector_data_company = pd.DataFrame({})\n",
    "for i in sector_data.ISSUER.unique():\n",
    "    df = sector_data[sector_data.ISSUER == i].iloc[[0]].reset_index()\n",
    "    index = df.notnull().sum(axis = 1).idxmax()\n",
    "    sector_data_company = sector_data_company.append(df.iloc[[index]])\n",
    "sector_data_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:38.344540Z",
     "start_time": "2021-05-11T16:02:38.329606Z"
    }
   },
   "outputs": [],
   "source": [
    "sector_data_company.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:38.360497Z",
     "start_time": "2021-05-11T16:02:38.347533Z"
    }
   },
   "outputs": [],
   "source": [
    "sector_mappings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__More companies mapped in Eikon database (370 vs 339), but more industries mapped in PermID database (313 vs 158).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry and sector analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all industries and sectors in which ECB invested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:38.376454Z",
     "start_time": "2021-05-11T16:02:38.361541Z"
    }
   },
   "outputs": [],
   "source": [
    "sector_data = eikon_data_complete[['ISIN','ICB Industry name','ICB Sector name','ICB Supersector name']]\n",
    "sector_data = sector_data[sector_data['ICB Industry name'] != \"Unable to collect data for the field 'TR.ICBIndustry' and some specific identifier(s).\"]\n",
    "# TODO: use regex to make it less stringent\n",
    "# sector_data.to_excel('output/test_sector_data.xlsx') # Export the resulting data to an excel file, create output folder if you want to use it!\n",
    "percentage_known_sectors = len(sector_data.index)/len(eikon_data_complete.index) # 50% of the rows removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Represent industries and sectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a pie chart to represent the number of times an industry, sector or supersector is present in the data (multiple bonds for the same company are counted separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:39.377119Z",
     "start_time": "2021-05-11T16:02:38.377452Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # TODO: add to requirements if used\n",
    "\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        if (pct > 2.4):\n",
    "            return '{p:.2f}%'.format(p=pct)\n",
    "        else:\n",
    "            return ''\n",
    "    return my_autopct\n",
    "\n",
    "def get_all_sectors(sector_type):\n",
    "    sector_data['number']=1 # TODO: count them in a cleaner way\n",
    "    sectors = sector_data[[sector_type, 'number']].groupby([sector_type]).sum()\n",
    "    sectors = sectors.sort_values(\"number\", axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)\n",
    "    return sectors\n",
    "    \n",
    "def make_pie_chart(column_name):\n",
    "    fig = plt.figure(figsize=(9,9))\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    sectors = get_all_sectors(column_name)\n",
    "    \n",
    "    sectors.plot(kind='pie', y='number', ax=ax, autopct=make_autopct(sectors['number']), fontsize=12, legend=False, rotatelabels=True, pctdistance=0.8)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(column_name+\"\\n\\n\\n\")\n",
    "\n",
    "make_pie_chart('ICB Supersector name')\n",
    "make_pie_chart('ICB Sector name')\n",
    "make_pie_chart('ICB Industry name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T18:14:25.820905Z",
     "start_time": "2021-05-03T18:14:25.802394Z"
    }
   },
   "source": [
    "## Which industries and sectors are green?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: automate this process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sector is considered green if it is in the list of \"Green economy sectors\" by Igor Mishevski.\n",
    "https://medium.com/@mishevski/green-economy-sectors-ceecabeec7f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:39.393079Z",
     "start_time": "2021-05-11T16:02:39.378119Z"
    }
   },
   "outputs": [],
   "source": [
    "industries = get_all_sectors('ICB Industry name')\n",
    "super_sectors = get_all_sectors('ICB Supersector name')\n",
    "sectors = get_all_sectors('ICB Sector name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:39.408406Z",
     "start_time": "2021-05-11T16:02:39.395074Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_green_sectors = [\"Real Estate\", \"Energy\", \"Oil, Gas and Coal\"] # Buildings, Energy supply, ... TODO: update list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:39.423996Z",
     "start_time": "2021-05-11T16:02:39.410034Z"
    }
   },
   "outputs": [],
   "source": [
    "industries[\"green\"]=0\n",
    "super_sectors[\"green\"]=0\n",
    "sectors[\"green\"]=0\n",
    "for i in range(0, len(industries.index)):\n",
    "    if industries.index[i] in list_of_green_sectors:\n",
    "        industries[\"green\"][i]=1\n",
    "    if super_sectors.index[i] in list_of_green_sectors:\n",
    "        super_sectors[\"green\"][i]=1\n",
    "    if sectors.index[i] in list_of_green_sectors:\n",
    "        sectors[\"green\"][i]=1\n",
    "print(industries)\n",
    "print(super_sectors)\n",
    "print(sectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:39.440001Z",
     "start_time": "2021-05-11T16:02:39.424993Z"
    }
   },
   "outputs": [],
   "source": [
    " def show_table(column_names, row_names, content):\n",
    "    fig, ax = plt.subplots() \n",
    "    ax.set_axis_off() \n",
    "    table = ax.table( \n",
    "        cellText = content,  \n",
    "        rowLabels = row_names,  \n",
    "        colLabels = column_names, \n",
    "        rowColours =[\"c\"] * len(row_names),  \n",
    "        colColours =[\"c\"] * len(column_names), \n",
    "        cellLoc ='center',  \n",
    "        loc ='upper left')         \n",
    "\n",
    "    ax.set_title('Percentage of industries or sectors that is green', \n",
    "                 fontweight =\"bold\") \n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:39.660815Z",
     "start_time": "2021-05-11T16:02:39.440950Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the percentage of represented industries considered green\n",
    "percentage_industries_green = industries[\"green\"].sum()/len(industries.index)\n",
    "percentage_super_sectors_green = super_sectors[\"green\"].sum()/len(super_sectors.index)\n",
    "percentage_sectors_green = sectors[\"green\"].sum()/len(sectors.index)\n",
    "\n",
    "# Calculate the percentage of represented bonds in green industries\n",
    "percentage_bonds_green_industries = (industries[\"green\"]*industries[\"number\"]).sum()/industries[\"number\"].sum()\n",
    "percentage_bonds_green_super_sectors = (super_sectors[\"green\"]*super_sectors[\"number\"]).sum()/super_sectors[\"number\"].sum()\n",
    "percentage_bonds_green_sectors = (sectors[\"green\"]*sectors[\"number\"]).sum()/sectors[\"number\"].sum()\n",
    "\n",
    "show_table([\"Compared to number of sectors\", \"Compared to number of bonds\"], [\"Industries\", \"Super sectors\", \"Sectors\"],\n",
    "           [[percentage_industries_green.round(3), percentage_bonds_green_industries.round(3)],\n",
    "            [percentage_super_sectors_green.round(3), percentage_bonds_green_super_sectors.round(3)],\n",
    "            [percentage_sectors_green.round(3), percentage_bonds_green_sectors.round(3)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CO2 Data/Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Spaghetti plot CO$_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:39.976372Z",
     "start_time": "2021-05-11T16:02:39.661816Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "co2_data = eikon_data_complete[[\"ISSUER\", \"CO2\", \"CO2_1\"]] #compnay name and CO2 subset \n",
    "company_co2_data = co2_data.drop_duplicates(subset= [\"ISSUER\"]) #Unique company name subset \n",
    "company_co2_data = company_co2_data[(company_co2_data.CO2 != '0') & (company_co2_data.CO2_1 != '0')] #not null value for CO2\n",
    "company_co2_data = company_co2_data.reset_index() #resets index\n",
    "company_co2_data = company_co2_data.drop(columns=[\"index\"]) #removes extra column\n",
    "company_co2_data = company_co2_data.replace(to_replace = '[,]', value ='.', regex=True) #making decimal points legible\n",
    "company_co2_data['CO2'] =company_co2_data['CO2'].astype(float) #converting numbers to floats \n",
    "company_co2_data['CO2_1'] =company_co2_data['CO2_1'].astype(float)\n",
    "\n",
    "#overall slope increase or decrease \n",
    "slopes = company_co2_data['CO2_1'] - company_co2_data['CO2']\n",
    "slopes.sum() #shows an overall decrease in total emissions **Could cluster by sector. Hard to do anything else with 2 data points*\n",
    "\n",
    "\n",
    "#making data easier to graph \n",
    "co2graph_data = company_co2_data[[\"CO2\", \"CO2_1\"]]\n",
    "co2graph_data = co2graph_data.transpose()\n",
    "co2graph_data.insert(0, \"x\", [0, 1], True)\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "palette = plt.get_cmap('Set1')\n",
    "\n",
    "#spaghetti plot of CO2 emissions \n",
    "plt.figure(figsize=(20,20))\n",
    "for column in co2graph_data.drop(columns=[\"x\"], axis=1):\n",
    "    plt.plot(co2graph_data[\"x\"], co2graph_data[column], marker='', linewidth=1, alpha=0.9)\n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Histogram change in CO$_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:40.420054Z",
     "start_time": "2021-05-11T16:02:39.977972Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(x=slopes, bins=7,alpha=0.7)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(r'Histogram of the change in nomalized CO$_2$ emission during the CSPP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### emission of 2021 as a function of the emission in 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:40.611584Z",
     "start_time": "2021-05-11T16:02:40.424044Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(company_co2_data[\"CO2\"],company_co2_data[\"CO2_1\"],'o')\n",
    "plt.title(\"emission of 2021 as a function of the emission in 2015\", size=15)\n",
    "plt.xlabel(\"emission in 2015\", size=15)\n",
    "plt.ylabel(\"emission in 2021\",size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make a linear fit through for this graph (see github of course: data analytics > radient_descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:43.842344Z",
     "start_time": "2021-05-11T16:02:40.613538Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# We will use the module Linear Regression of sklearn to perform the analysis\n",
    "# Initialize the model\n",
    "ols = LinearRegression()\n",
    "# Fit the model to the data\n",
    "ols.fit(company_co2_data[\"CO2\"].values.reshape(-1, 1),company_co2_data[\"CO2_1\"])\n",
    "\n",
    "print('Fit is of the form:',np.round(ols.intercept_,3),'+',np.round(ols.coef_[0],3),'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As the slope is slightly below one, we can conclude that in general, the normalized CO$_2$ emission decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:44.112623Z",
     "start_time": "2021-05-11T16:02:43.844340Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# plot of data\n",
    "plt.plot(company_co2_data[\"CO2\"],company_co2_data[\"CO2_1\"],'o',label=\"data\")\n",
    "\n",
    "# plot of fit\n",
    "x = np.arange(0,max((company_co2_data[\"CO2\"])+100))\n",
    "y = ols.intercept_ + ols.coef_[0]*x\n",
    "plt.plot(x,y,'r-',label=\"fit\")\n",
    "\n",
    "# making a nice figure\n",
    "plt.title(\"emission of 2021 as a function of the emission in 2015\", size=15)\n",
    "plt.xlabel(\"emission in 2015\", size=15)\n",
    "plt.ylabel(\"emission in 2021\",size=15)\n",
    "plt.legend(fontsize=\"15\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESG data/plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for cleaning the ESG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:44.128623Z",
     "start_time": "2021-05-11T16:02:44.114619Z"
    }
   },
   "outputs": [],
   "source": [
    "def cleaning_esg_data(df):\n",
    "    column_names_esg_company_data = [\"ISSUER\", \"ESG Score 2015\", \"ESG Score 2016\", \"ESG Score 2017\", \n",
    "                                \"ESG Score 2018\", \"ESG Score 2019\", \"ESG Score 2020\", \n",
    "                                \"ESG Score 2021\"]\n",
    "    #started cleaning data as above \n",
    "    esg_data = df[column_names_esg_company_data]\n",
    "    esg_company_data = esg_data.drop_duplicates(subset= [\"ISSUER\"])\n",
    "    esg_company_data = esg_company_data.replace(to_replace = '[,]', value ='.', regex=True)\n",
    "\n",
    "    # replace zeros with nans, as these are easier to replace\n",
    "    esg_company_data = esg_company_data.replace(to_replace = '0', value = np.nan) \n",
    "\n",
    "    # remove rows with no data for ESG score\n",
    "    esg_company_data.dropna(axis=0, how='all', \n",
    "                            subset=column_names_esg_company_data[1:8], inplace=True)\n",
    "\n",
    "    #converting all numbers to floats \n",
    "    for column_name in column_names_esg_company_data[1:8]:\n",
    "        esg_company_data[column_name] = esg_company_data[column_name].astype(float)\n",
    "\n",
    "    # interpolate data that is missing\n",
    "    esg_company_data.iloc[:,1:] = esg_company_data.iloc[:,1:].interpolate(method='linear', axis=1, limit_direction='both',\n",
    "                                                                          inplace=False)\n",
    "    #TODO: If we want to keep this apart, we can make a new variable holding the filled in dataframe\n",
    "\n",
    "    # reset the indexes\n",
    "    esg_company_data = esg_company_data.reset_index()\n",
    "    esg_company_data = esg_company_data.drop(columns=[\"index\"])\n",
    "    \n",
    "    return esg_company_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:44.192430Z",
     "start_time": "2021-05-11T16:02:44.130575Z"
    }
   },
   "outputs": [],
   "source": [
    "esg_company_data_holdings = cleaning_esg_data(eikon_data_complete)\n",
    "esg_company_data_eligible = cleaning_esg_data(eligible_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spaghetti plot ESG Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:44.590404Z",
     "start_time": "2021-05-11T16:02:44.193427Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "years = range(2015,2022)\n",
    "for index,row in esg_company_data_holdings.iterrows():\n",
    "    plt.plot(years,row[1:8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:44.622282Z",
     "start_time": "2021-05-11T16:02:44.591365Z"
    }
   },
   "outputs": [],
   "source": [
    "esg_company_data_holdings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:44.653199Z",
     "start_time": "2021-05-11T16:02:44.624277Z"
    }
   },
   "outputs": [],
   "source": [
    "esg_company_data_eligible.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:44.843659Z",
     "start_time": "2021-05-11T16:02:44.656193Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "years = range(2015,2022)\n",
    "\n",
    "mean_holdings = esg_company_data_holdings.mean().values\n",
    "error_holdings = esg_company_data_holdings.std().values\n",
    "\n",
    "mean_eligible = esg_company_data_eligible.mean().values\n",
    "error_eligible = esg_company_data_eligible.std().values\n",
    "\n",
    "plt.errorbar(years, mean_holdings, yerr=error_holdings, ecolor='r', capsize=10, label=\"holdings\")\n",
    "\n",
    "plt.errorbar(years, mean_eligible, yerr=error_eligible, ecolor='y', capsize=10, label=\"eligible\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this figure, we can clearly see that the average ESG-score of the companies increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:45.145068Z",
     "start_time": "2021-05-11T16:02:44.844344Z"
    }
   },
   "outputs": [],
   "source": [
    "esg_company_data_holdings.iloc[:,1:].boxplot(figsize=(10,10),color='y')\n",
    "esg_company_data_eligible.iloc[:,1:].boxplot(figsize=(10,10),color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESG evolution of each company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit the evolution of each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:45.272588Z",
     "start_time": "2021-05-11T16:02:45.146024Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def linReg_esg_company_data(esg_company_data):\n",
    "    list_of_coef = []\n",
    "    list_of_intercepts = []\n",
    "    years = np.arange(0,7)\n",
    "    # We will use the module Linear Regression of sklearn to perform the analysis\n",
    "    # Initialize the model\n",
    "    ols = LinearRegression()\n",
    "    # Fit the model to the data\n",
    "    for index,row in esg_company_data.iterrows():\n",
    "        resultOfFit = ols.fit(years.reshape(-1, 1),row[1:8])\n",
    "        list_of_coef.append(resultOfFit.coef_[0])\n",
    "        list_of_intercepts.append(resultOfFit.intercept_)\n",
    "    return list_of_coef,list_of_intercepts\n",
    "\n",
    "list_of_coef_holdings, list_of_intercepts_holdings = linReg_esg_company_data(esg_company_data_holdings)\n",
    "list_of_coef_eligible, list_of_intercepts_eligible = linReg_esg_company_data(esg_company_data_eligible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a boxplot of the coefficients of these fits. This should give an indication about the general evolution (increase vs decrease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:45.384336Z",
     "start_time": "2021-05-11T16:02:45.273634Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.boxplot([list_of_coef_holdings, list_of_coef_eligible], \"y\")\n",
    "plt.xticks(ticks=[1,2], labels=[\"holdings\", \"eligible\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure shows us that only roughly 25% of companies have a negative slope, while the other 75% have an increasin ESG score.\n",
    "\n",
    "Let us now try to find a relation between the initial ESG score and the most recent one. This can be done by plotting and calculating the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:45.511839Z",
     "start_time": "2021-05-11T16:02:45.386327Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(list_of_intercepts_holdings,list_of_coef_holdings, 'b.')\n",
    "plt.plot(list_of_intercepts_eligible,list_of_coef_eligible, 'y.')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:02:45.527716Z",
     "start_time": "2021-05-11T16:02:45.513436Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"holdings:\\n\", np.corrcoef(list_of_coef_holdings, list_of_intercepts_holdings),\n",
    "      \"\\n eligible:\\n\", np.corrcoef(list_of_coef_eligible, list_of_intercepts_eligible))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some negative correlation ==> lower initial value, faster increase in ESG score."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "c66e68dc8effbb73dddbef0493505d10f36de5f905f8b8ed3ac14ee9c27e255b"
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 277.4,
   "position": {
    "height": "299.4px",
    "left": "971.4px",
    "right": "20px",
    "top": "98px",
    "width": "493px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
