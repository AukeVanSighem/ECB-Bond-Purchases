{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:13.186785Z",
     "start_time": "2021-05-03T19:31:03.483423Z"
    }
   },
   "outputs": [],
   "source": [
    "# List of modules that are not installed in the course\n",
    "!pip install OpenPermID\n",
    "!pip install Levenshtein\n",
    "!pip install geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:13.764517Z",
     "start_time": "2021-05-03T19:31:13.287669Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Downloading all bonds ever owned in CSPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:14.015070Z",
     "start_time": "2021-05-03T19:31:13.859776Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import requests, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:14.140377Z",
     "start_time": "2021-05-03T19:31:14.126519Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This function gets the csv from the url and places the new data in a dictionary with keys = ISIN,\n",
    "# and value = [NCB, ISSUER, MATURITY DATE, COUPON RATE]\n",
    "def downloadDataToDictionary(url,dictionary):\n",
    "    r = requests.get(url) # create HTTP response object\n",
    "    nameCompany = '' # make a string for the company name \n",
    "                     # (do this here so that is in scope of whole function)\n",
    "    if r.status_code != 200: return # if website wasn't accessed in the right way, \n",
    "                                    # stop the function\n",
    "    # this for loop loops through all the lines of the retrieved csv-file, except for the heading\n",
    "    for line in r.text.split('\\r\\n')[1:]:\n",
    "        if not re.search(r'[a-z]',line): continue # if the line doesn't contain letters, \n",
    "                                                  # go to the next line\n",
    "        if re.search(r',+$',line): line = re.sub(r',+$',r'',line) # remove commas at end of line\n",
    "        splitLine = line.split(',')\n",
    "        if len(splitLine) < 5: continue # We expect at least 5 items as we want 5 columns \n",
    "                                        # and name could lead to additional columns\n",
    "        if re.search(r'(?:\\\".*,.*\\\")',line): # searches commas between \" as these are part of the name \n",
    "                                             # and shouldn't be split\n",
    "            nameCompany = re.search(r'(?:\\\".*,.*\\\")',line).group(0) \n",
    "                                             # name of the company is between the \"\"\n",
    "            nameCompany = re.sub(r\"\\\"\",\"\",nameCompany) # remove the \"\"\n",
    "        else:\n",
    "            for str in splitLine:\n",
    "                re.sub('\\\"','',str)\n",
    "            nameCompany = splitLine[2]\n",
    "        if (splitLine[1] not in dictionary): # only add new ISINs to the dictionary\n",
    "            dictionary[splitLine[1]] = [splitLine[0], nameCompany, splitLine[-2], splitLine[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:45.056387Z",
     "start_time": "2021-05-03T19:31:14.256710Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dateToDownload = datetime.date(2017, 6, 23)\n",
    "change_url_date = datetime.date(2020, 3, 27)\n",
    "end_date = datetime.date(2021,4,23)\n",
    "delta = datetime.timedelta(days=7)\n",
    "dictionaryBondsECB = {}\n",
    "\n",
    "while dateToDownload <= change_url_date:\n",
    "    date = dateToDownload.strftime(\"%Y%m%d\")\n",
    "    url = \"https://www.ecb.europa.eu/mopo/pdf/CSPPholdings_\"+date+\".csv\"\n",
    "    downloadDataToDictionary(url,dictionaryBondsECB)\n",
    "    dateToDownload += delta\n",
    "dateToDownload+delta\n",
    "while dateToDownload <= end_date:\n",
    "    date = dateToDownload.strftime(\"%Y%m%d\")\n",
    "    url = \"https://www.ecb.europa.eu/mopo/pdf/CSPP_PEPP_corporate_bond_holdings_\"+date+\".csv\"\n",
    "    downloadDataToDictionary(url,dictionaryBondsECB)\n",
    "    dateToDownload += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:45.199829Z",
     "start_time": "2021-05-03T19:31:45.153685Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matrixData = [] # 2D array with row per ISIN and columns for different data\n",
    "for ISIN, dataInDictionary in dictionaryBondsECB.items():\n",
    "    item = [ISIN] + dataInDictionary\n",
    "    matrixData.append(item)\n",
    "holdingsECB = pd.DataFrame(matrixData, columns=[\"ISIN\",\"NCB\",\"ISSUER\",\"MATURITY DATE\",\"COUPON RATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:45.385869Z",
     "start_time": "2021-05-03T19:31:45.356421Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Export data to csv for easy retrieval on computers with Eikon\n",
    "holdingsECB.to_csv('data/holdingsECB.csv',index=False,sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ECB green bonds that are listed on Euronext stock exchange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:38:39.366646Z",
     "start_time": "2021-05-03T17:38:39.024567Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#reading data of green bonds listed on Euronext \n",
    "euronext_greenbonds = pd.read_excel(\"data/Euronext-Green-Bond-List.xlsx\", header=0)\n",
    "euronext_greenbonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:38:39.382058Z",
     "start_time": "2021-05-03T17:38:39.369095Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Getting the ISIN of the Euronext green bonds \n",
    "euronext_greenbond_isin = euronext_greenbonds[\"ISIN\"]\n",
    "euronext_greenbond_isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:38:39.414298Z",
     "start_time": "2021-05-03T17:38:39.386048Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Comparing the ISINs of the ECB and Euronext green bonds and returning matches \n",
    "ecbgreenbonds = holdingsECB[(holdingsECB[\"ISIN\"].isin(euronext_greenbond_isin))]\n",
    "ecbgreenbonds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Find Sectors and Locations of Companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Make this function work for all the ECB bonds instead of just the ones from April 2nd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:38:39.634493Z",
     "start_time": "2021-05-03T17:38:39.417263Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Requirements\n",
    "from OpenPermID import OpenPermID\n",
    "import Levenshtein\n",
    "import geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:38:39.650414Z",
     "start_time": "2021-05-03T17:38:39.637518Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Gain access to the permid database\n",
    "opid = OpenPermID()\n",
    "opid.set_access_token(\"r95vEAhvmucG8iNGtsP17hjbgUGMhz4j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:42:35.252854Z",
     "start_time": "2021-05-03T17:38:39.651370Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "holdings20210402 = pd.read_csv(\"data/CSPP_PEPP_corporate_bond_holdings_20210402.csv\", header=0, encoding='latin-1') #TODO: remove!\n",
    "companies = holdings20210402.ISSUER.astype('string').unique()\n",
    "permid_mappings = pd.DataFrame({})\n",
    "unmapped_companies = []\n",
    "\n",
    "for company in companies:\n",
    "    \n",
    "    # In case of connection error, allow it to try at most 5 times\n",
    "    err, count = 0, 0\n",
    "    while (err != None and count < 5):\n",
    "        output, err = opid.search(company)\n",
    "    if err != None:\n",
    "        unmapped_companies.append(company)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    df = output['organizations']\n",
    "    if len(df) == 0:\n",
    "        permid = np.NaN\n",
    "        name = np.NaN\n",
    "    elif len(df) == 1:\n",
    "        permid = df.iloc[0,0].split('/')[-1]\n",
    "        name = df.iloc[0,1]\n",
    "    else:\n",
    "        # If multiple records are return, choose the record which the company name is the most similar to the keyword\n",
    "        similarityScores = df.organizationName.apply(lambda x: Levenshtein.ratio(company, x))\n",
    "        max_index = similarityScores.idxmax()\n",
    "        permid = df.iloc[max_index, 0].split('/')[-1]\n",
    "        name = df.iloc[max_index, 1]\n",
    "    permid_mappings = permid_mappings.append(pd.DataFrame({'keyword':[company], 'companyName': [name], 'PermID':[permid]}))\n",
    "    \n",
    "permid_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:47:27.728276Z",
     "start_time": "2021-05-03T17:42:35.254847Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "permids = permid_mappings.PermID.dropna().astype('string')\n",
    "sector_lookups = pd.DataFrame({})\n",
    "unsuccessful_lookups = []\n",
    "\n",
    "for permid in permids:\n",
    "    \n",
    "    # In case of connection error, allow it to try at most 5 times\n",
    "    err, count = 0, 0\n",
    "    while (err != None and count < 5):\n",
    "        output, err = opid.lookup(permid)\n",
    "    if err != None:\n",
    "        unsuccessful_lookups.append(permid)\n",
    "        continue\n",
    "\n",
    "    if \"hasPrimaryBusinessSector\" in output.columns:\n",
    "        sector_info = output.loc[:, 'hasPrimaryBusinessSector': 'hasPrimaryIndustryGroup']\n",
    "        sector_info = sector_info.applymap(lambda x: x.split('/')[-1])\n",
    "    if \"isIncorporatedIn\" in output.columns:\n",
    "        loc_info = output.loc[:, 'isIncorporatedIn': 'isDomiciledIn']\n",
    "        loc_info = loc_info.applymap(lambda x: x.split('/')[-2])\n",
    "        \n",
    "    row = pd.DataFrame({'PermID': [permid]})\n",
    "    row = pd.concat([row, sector_info], axis = 1) if type(sector_info) == pd.DataFrame else row\n",
    "    row = pd.concat([row, loc_info], axis = 1) if type(loc_info) == pd.DataFrame else row\n",
    "    sector_lookups = sector_lookups.append(row)\n",
    "    \n",
    "    sector_info, loc_info = None, None\n",
    "\n",
    "sector_lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:48:16.288686Z",
     "start_time": "2021-05-03T17:47:27.730170Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sector_lookups_converted = sector_lookups.copy()\n",
    "sector_types = sector_lookups.columns[1:4]\n",
    "for sector_type in sector_types:\n",
    "    sector_dict = {}\n",
    "    sectors = sector_lookups.loc[:, sector_type].dropna().astype('string').unique()\n",
    "    for sector in sectors:\n",
    "        output, err = opid.lookup(sector)\n",
    "        sector_dict[sector] = output.iloc[0, -1]\n",
    "    sector_lookups_converted[sector_type] = sector_lookups[sector_type].fillna('missing').astype('string').apply(lambda x: np.NaN if x == 'missing' else sector_dict[x])\n",
    "\n",
    "loc_types = sector_lookups.columns[4:]\n",
    "for loc_type in loc_types:\n",
    "    loc_dict = {}\n",
    "    locs = sector_lookups.loc[:, loc_type].dropna().astype('string').unique()\n",
    "    for loc in locs:\n",
    "        g = geocoder.geonames(loc, method='details', key='brian1998716')\n",
    "        loc_dict[loc] = g.address\n",
    "    sector_lookups_converted[loc_type] = sector_lookups[loc_type].fillna('missing').astype('string').apply(lambda x: np.NaN if x == 'missing' else loc_dict[x])\n",
    "\n",
    "sector_lookups_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:48:16.294182Z",
     "start_time": "2021-05-03T17:37:53.283Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sector_mappings = pd.merge(permid_mappings, sector_lookups_converted, how = 'left', on = 'PermID')\n",
    "sector_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:48:16.295180Z",
     "start_time": "2021-05-03T17:37:53.287Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sector_mappings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Read all the Eikon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:45.571816Z",
     "start_time": "2021-05-03T19:31:45.530589Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eikon_data_folder = \"data/\"\n",
    "eikon_data_environment = pd.read_csv(eikon_data_folder+\"holdingsECBEnvironment.txt\",sep=\"\\t\")\n",
    "# TODO: remove right, empty columns from data frame\n",
    "eikon_data_general = pd.read_csv(eikon_data_folder+\"holdingsECBGeneralInfo.txt\",sep=\"\\t\")\n",
    "eikon_data_industry = pd.read_csv(eikon_data_folder+\"holdingsECBIndustryAndSector.txt\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:45.930702Z",
     "start_time": "2021-05-03T19:31:45.900749Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eikon_data_merged = eikon_data_general.merge(eikon_data_environment, \"left\", \"ISIN\") #append environment\n",
    "eikon_data_complete = eikon_data_merged.merge(eikon_data_industry, \"left\", \"ISIN\") # appended industry\n",
    "eikon_data_complete.rename(columns={'CO2.1': 'CO2_1'}, inplace=True) #changed column name to prevent syntax errors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Industry and sector analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Get all industries and sectors in which ECB invested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:46.418587Z",
     "start_time": "2021-05-03T19:31:46.405446Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sector_data = eikon_data_complete[['ISIN','ICB Industry name','ICB Sector name','ICB Supersector name']]\n",
    "sector_data = sector_data[sector_data['ICB Industry name'] != \"Unable to collect data for the field 'TR.ICBIndustry' and some specific identifier(s).\"]\n",
    "# TODO: use regex to make it less stringent\n",
    "# sector_data.to_excel('output/test_sector_data.xlsx') # Export the resulting data to an excel file, create output folder if you want to use it!\n",
    "percentage_known_sectors = len(sector_data.index)/len(eikon_data_complete.index) # 50% of the rows removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Represent industries and sectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a pie chart to represent the number of times an industry, sector or supersector is present in the data (multiple bonds for the same company are counted separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:48.577374Z",
     "start_time": "2021-05-03T19:31:46.889705Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # TODO: add to requirements if used\n",
    "\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        if (pct > 2.4):\n",
    "            return '{p:.2f}%'.format(p=pct)\n",
    "        else:\n",
    "            return ''\n",
    "    return my_autopct\n",
    "\n",
    "def get_all_sectors(sector_type):\n",
    "    sector_data['number']=1 # TODO: count them in a cleaner way\n",
    "    sectors = sector_data[[sector_type, 'number']].groupby([sector_type]).sum()\n",
    "    sectors = sectors.sort_values(\"number\", axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)\n",
    "    return sectors\n",
    "    \n",
    "def make_pie_chart(column_name):\n",
    "    fig = plt.figure(figsize=(9,9))\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    sectors = get_all_sectors(column_name)\n",
    "    \n",
    "    sectors.plot(kind='pie', y='number', ax=ax, autopct=make_autopct(sectors['number']), fontsize=12, legend=False, rotatelabels=True, pctdistance=0.8)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(column_name+\"\\n\\n\\n\")\n",
    "\n",
    "make_pie_chart('ICB Supersector name')\n",
    "make_pie_chart('ICB Sector name')\n",
    "make_pie_chart('ICB Industry name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T18:14:25.820905Z",
     "start_time": "2021-05-03T18:14:25.802394Z"
    }
   },
   "source": [
    "## Which industries and sectors are green?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: automate this process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sector is considered green if it is in the list of \"Green economy sectors\" by Igor Mishevski.\n",
    "https://medium.com/@mishevski/green-economy-sectors-ceecabeec7f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:49.140824Z",
     "start_time": "2021-05-03T19:31:49.110823Z"
    }
   },
   "outputs": [],
   "source": [
    "industries = get_all_sectors('ICB Industry name')\n",
    "super_sectors = get_all_sectors('ICB Supersector name')\n",
    "sectors = get_all_sectors('ICB Sector name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:49.707999Z",
     "start_time": "2021-05-03T19:31:49.695335Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_green_sectors = [\"Real Estate\", \"Energy\", \"Oil, Gas and Coal\"] # Buildings, Energy supply, ... TODO: update list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:50.211676Z",
     "start_time": "2021-05-03T19:31:50.198706Z"
    }
   },
   "outputs": [],
   "source": [
    "industries[\"green\"]=0\n",
    "super_sectors[\"green\"]=0\n",
    "sectors[\"green\"]=0\n",
    "for i in range(0, len(industries.index)):\n",
    "    if industries.index[i] in list_of_green_sectors:\n",
    "        industries[\"green\"][i]=1\n",
    "    if super_sectors.index[i] in list_of_green_sectors:\n",
    "        super_sectors[\"green\"][i]=1\n",
    "    if sectors.index[i] in list_of_green_sectors:\n",
    "        sectors[\"green\"][i]=1\n",
    "print(industries)\n",
    "print(super_sectors)\n",
    "print(sectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:50.788756Z",
     "start_time": "2021-05-03T19:31:50.775241Z"
    }
   },
   "outputs": [],
   "source": [
    " def show_table(column_names, row_names, content):\n",
    "    fig, ax = plt.subplots() \n",
    "    ax.set_axis_off() \n",
    "    table = ax.table( \n",
    "        cellText = content,  \n",
    "        rowLabels = row_names,  \n",
    "        colLabels = column_names, \n",
    "        rowColours =[\"c\"] * len(row_names),  \n",
    "        colColours =[\"c\"] * len(column_names), \n",
    "        cellLoc ='center',  \n",
    "        loc ='upper left')         \n",
    "\n",
    "    ax.set_title('Percentage of industries or sectors that is green', \n",
    "                 fontweight =\"bold\") \n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:31:51.633037Z",
     "start_time": "2021-05-03T19:31:51.354137Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the percentage of represented industries considered green\n",
    "percentage_industries_green = industries[\"green\"].sum()/len(industries.index)\n",
    "percentage_super_sectors_green = super_sectors[\"green\"].sum()/len(super_sectors.index)\n",
    "percentage_sectors_green = sectors[\"green\"].sum()/len(sectors.index)\n",
    "\n",
    "# Calculate the percentage of represented bonds in green industries\n",
    "percentage_bonds_green_industries = (industries[\"green\"]*industries[\"number\"]).sum()/industries[\"number\"].sum()\n",
    "percentage_bonds_green_super_sectors = (super_sectors[\"green\"]*super_sectors[\"number\"]).sum()/super_sectors[\"number\"].sum()\n",
    "percentage_bonds_green_sectors = (sectors[\"green\"]*sectors[\"number\"]).sum()/sectors[\"number\"].sum()\n",
    "\n",
    "show_table([\"Compared to number of sectors\", \"Compared to number of bonds\"], [\"Industries\", \"Super sectors\", \"Sectors\"],\n",
    "           [[percentage_industries_green.round(3), percentage_bonds_green_industries.round(3)],\n",
    "            [percentage_super_sectors_green.round(3), percentage_bonds_green_super_sectors.round(3)],\n",
    "            [percentage_sectors_green.round(3), percentage_bonds_green_sectors.round(3)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CO2 Data/Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Spaghetti plot CO$_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:52:05.736598Z",
     "start_time": "2021-05-03T17:52:05.329737Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "co2_data = eikon_data_complete[[\"ISSUER\", \"CO2\", \"CO2_1\"]] #compnay name and CO2 subset \n",
    "company_co2_data = co2_data.drop_duplicates(subset= [\"ISSUER\"]) #Unique company name subset \n",
    "company_co2_data = company_co2_data[(company_co2_data.CO2 != '0') & (company_co2_data.CO2_1 != '0')] #not null value for CO2\n",
    "company_co2_data = company_co2_data.reset_index() #resets index\n",
    "company_co2_data = company_co2_data.drop(columns=[\"index\"]) #removes extra column\n",
    "company_co2_data = company_co2_data.replace(to_replace = '[,]', value ='.', regex=True) #making decimal points legible\n",
    "company_co2_data['CO2'] =company_co2_data['CO2'].astype(float) #converting numbers to floats \n",
    "company_co2_data['CO2_1'] =company_co2_data['CO2_1'].astype(float)\n",
    "\n",
    "#overall slope increase or decrease \n",
    "slopes = company_co2_data['CO2_1'] - company_co2_data['CO2']\n",
    "slopes.sum() #shows an overall decrease in total emissions **Could cluster by sector. Hard to do anything else with 2 data points*\n",
    "\n",
    "\n",
    "#making data easier to graph \n",
    "co2graph_data = company_co2_data[[\"CO2\", \"CO2_1\"]]\n",
    "co2graph_data = co2graph_data.transpose()\n",
    "co2graph_data.insert(0, \"x\", [0, 1], True)\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "palette = plt.get_cmap('Set1')\n",
    "\n",
    "#spaghetti plot of CO2 emissions \n",
    "plt.figure(figsize=(20,20))\n",
    "for column in co2graph_data.drop(columns=[\"x\"], axis=1):\n",
    "    plt.plot(co2graph_data[\"x\"], co2graph_data[column], marker='', linewidth=1, alpha=0.9)\n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Histogram change in CO$_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:52:21.069656Z",
     "start_time": "2021-05-03T17:52:20.531809Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(x=slopes, bins=7,alpha=0.7)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(r'Histogram of the change in nomalized CO$_2$ emission during the CSPP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### emission of 2021 as a function of the emission in 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:52:24.805870Z",
     "start_time": "2021-05-03T17:52:24.579810Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(company_co2_data[\"CO2\"],company_co2_data[\"CO2_1\"],'o')\n",
    "plt.title(\"emission of 2021 as a function of the emission in 2015\", size=15)\n",
    "plt.xlabel(\"emission in 2015\", size=15)\n",
    "plt.ylabel(\"emission in 2021\",size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make a linear fit through for this graph (see github of course: data analytics > radient_descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:52:32.809546Z",
     "start_time": "2021-05-03T17:52:27.663613Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# We will use the module Linear Regression of sklearn to perform the analysis\n",
    "# Initialize the model\n",
    "ols = LinearRegression()\n",
    "# Fit the model to the data\n",
    "ols.fit(company_co2_data[\"CO2\"].values.reshape(-1, 1),company_co2_data[\"CO2_1\"])\n",
    "\n",
    "print('Fit is of the form:',np.round(ols.intercept_,3),'+',np.round(ols.coef_[0],3),'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As the slope is slightly below one, we can conclude that in general, the normalized CO$_2$ emission decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:52:33.654036Z",
     "start_time": "2021-05-03T17:52:33.309615Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# plot of data\n",
    "plt.plot(company_co2_data[\"CO2\"],company_co2_data[\"CO2_1\"],'o',label=\"data\")\n",
    "\n",
    "# plot of fit\n",
    "x = np.arange(0,max((company_co2_data[\"CO2\"])+100))\n",
    "y = ols.intercept_ + ols.coef_[0]*x\n",
    "plt.plot(x,y,'r-',label=\"fit\")\n",
    "\n",
    "# making a nice figure\n",
    "plt.title(\"emission of 2021 as a function of the emission in 2015\", size=15)\n",
    "plt.xlabel(\"emission in 2015\", size=15)\n",
    "plt.ylabel(\"emission in 2021\",size=15)\n",
    "plt.legend(fontsize=\"15\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESG data/plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:52:34.216908Z",
     "start_time": "2021-05-03T17:52:34.173286Z"
    }
   },
   "outputs": [],
   "source": [
    "column_names_esg_company_data = [\"ISSUER\", \"ESG Score 2015\", \"ESG Score 2016\", \"ESG Score 2017\", \n",
    "                                \"ESG Score 2018\", \"ESG Score 2019\", \"ESG Score 2020\", \n",
    "                                \"ESG Score 2021\"]\n",
    "#started cleaning data as above \n",
    "esg_data = eikon_data_complete[column_names_esg_company_data]\n",
    "esg_company_data = esg_data.drop_duplicates(subset= [\"ISSUER\"])\n",
    "esg_company_data = esg_company_data.replace(to_replace = '[,]', value ='.', regex=True)\n",
    "\n",
    "# replace zeros with nans, as these are easier to replace\n",
    "esg_company_data = esg_company_data.replace(to_replace = '0', value = np.nan) \n",
    "\n",
    "# remove rows with no data for ESG score\n",
    "esg_company_data.dropna(axis=0, how='all', \n",
    "                        subset=column_names_esg_company_data[1:8], inplace=True)\n",
    "\n",
    "#converting all numbers to floats \n",
    "for column_name in column_names_esg_company_data[1:8]:\n",
    "    esg_company_data[column_name] = esg_company_data[column_name].astype(float)\n",
    "\n",
    "# interpolate data that is missing\n",
    "esg_company_data.iloc[:,1:] = esg_company_data.iloc[:,1:].interpolate(method='linear', axis=1, limit_direction='both',\n",
    "                                                                      inplace=False)\n",
    "#TODO: If we want to keep this apart, we can make a new variable holding the filled in dataframe\n",
    "\n",
    "# reset the indexes\n",
    "esg_company_data = esg_company_data.reset_index()\n",
    "esg_company_data = esg_company_data.drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Spaghetti plot ESG Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:52:35.419820Z",
     "start_time": "2021-05-03T17:52:34.967804Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "years = range(2015,2022)\n",
    "for index,row in esg_company_data.iterrows():\n",
    "    plt.plot(years,row[1:8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Some Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:52:37.818225Z",
     "start_time": "2021-05-03T17:52:37.770274Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "esg_company_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:52:40.121437Z",
     "start_time": "2021-05-03T17:52:39.868692Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "years = range(2015,2022)\n",
    "\n",
    "mean = esg_company_data.mean().values\n",
    "error = esg_company_data.std().values\n",
    "\n",
    "max_values = esg_company_data.max().values\n",
    "min_values = esg_company_data.min().values\n",
    "\n",
    "plt.errorbar(years, mean, yerr=error, ecolor='r', capsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this figure, we can clearly see that the average ESG-score of the companies increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:52:42.646162Z",
     "start_time": "2021-05-03T17:52:42.336765Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "esg_company_data.iloc[:,1:].boxplot(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESG evolution of each company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit the evolution of each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:52:44.789212Z",
     "start_time": "2021-05-03T17:52:44.669940Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_coef = []\n",
    "list_of_intercepts = []\n",
    "years = np.arange(0,7)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# We will use the module Linear Regression of sklearn to perform the analysis\n",
    "# Initialize the model\n",
    "ols = LinearRegression()\n",
    "# Fit the model to the data\n",
    "for index,row in esg_company_data.iterrows():\n",
    "    resultOfFit = ols.fit(years.reshape(-1, 1),row[1:8])\n",
    "    list_of_coef.append(resultOfFit.coef_[0])\n",
    "    list_of_intercepts.append(resultOfFit.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a boxplot of the coefficients of these fits. This should give an indication about the general evolution (increase vs decrease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:52:46.484283Z",
     "start_time": "2021-05-03T17:52:46.338740Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,5))\n",
    "\n",
    "plt.boxplot(list_of_coef)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure shows us that only roughly 25% of companies have a negative slope, while the other 75% have an increasin ESG score.\n",
    "\n",
    "Let us now try to find a relation between the initial ESG score and the most recent one. This can be done by plotting and calculating the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:52:48.573815Z",
     "start_time": "2021-05-03T17:52:48.423155Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(list_of_intercepts,list_of_coef, 'b.')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T17:52:50.480961Z",
     "start_time": "2021-05-03T17:52:50.466763Z"
    }
   },
   "outputs": [],
   "source": [
    "np.corrcoef(list_of_coef, list_of_intercepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some negative correlation ==> lower initial value, faster increase in ESG score."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "c66e68dc8effbb73dddbef0493505d10f36de5f905f8b8ed3ac14ee9c27e255b"
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 277.4,
   "position": {
    "height": "299.4px",
    "left": "971.4px",
    "right": "20px",
    "top": "98px",
    "width": "493px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
