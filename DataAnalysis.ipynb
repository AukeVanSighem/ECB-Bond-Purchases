{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:39:25.106703Z",
     "start_time": "2021-05-13T17:39:16.051686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: OpenPermID in c:\\users\\auke\\anaconda3\\lib\\site-packages (0.5)\n",
      "Requirement already satisfied: requests in c:\\users\\auke\\anaconda3\\lib\\site-packages (from OpenPermID) (2.24.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\auke\\anaconda3\\lib\\site-packages (from OpenPermID) (1.1.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\auke\\anaconda3\\lib\\site-packages (from requests->OpenPermID) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\auke\\anaconda3\\lib\\site-packages (from requests->OpenPermID) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\auke\\anaconda3\\lib\\site-packages (from requests->OpenPermID) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\auke\\anaconda3\\lib\\site-packages (from requests->OpenPermID) (3.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\auke\\anaconda3\\lib\\site-packages (from pandas->OpenPermID) (1.19.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\auke\\anaconda3\\lib\\site-packages (from pandas->OpenPermID) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\auke\\anaconda3\\lib\\site-packages (from pandas->OpenPermID) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\auke\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->OpenPermID) (1.15.0)\n",
      "Requirement already satisfied: Levenshtein in c:\\users\\auke\\anaconda3\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\auke\\anaconda3\\lib\\site-packages (from Levenshtein) (50.3.1.post20201107)\n",
      "Requirement already satisfied: geocoder in c:\\users\\auke\\anaconda3\\lib\\site-packages (1.38.1)\n",
      "Requirement already satisfied: requests in c:\\users\\auke\\anaconda3\\lib\\site-packages (from geocoder) (2.24.0)\n",
      "Requirement already satisfied: click in c:\\users\\auke\\anaconda3\\lib\\site-packages (from geocoder) (7.1.2)\n",
      "Requirement already satisfied: future in c:\\users\\auke\\anaconda3\\lib\\site-packages (from geocoder) (0.18.2)\n",
      "Requirement already satisfied: ratelim in c:\\users\\auke\\anaconda3\\lib\\site-packages (from geocoder) (0.1.6)\n",
      "Requirement already satisfied: six in c:\\users\\auke\\anaconda3\\lib\\site-packages (from geocoder) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\auke\\anaconda3\\lib\\site-packages (from requests->geocoder) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\auke\\anaconda3\\lib\\site-packages (from requests->geocoder) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\auke\\anaconda3\\lib\\site-packages (from requests->geocoder) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\auke\\anaconda3\\lib\\site-packages (from requests->geocoder) (3.0.4)\n",
      "Requirement already satisfied: decorator in c:\\users\\auke\\anaconda3\\lib\\site-packages (from ratelim->geocoder) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "# List of modules that are not installed in the course\n",
    "!pip install OpenPermID\n",
    "!pip install Levenshtein\n",
    "!pip install geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:39:27.490341Z",
     "start_time": "2021-05-13T17:39:25.108701Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Downloading all bonds ever owned in CSPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:39:27.613993Z",
     "start_time": "2021-05-13T17:39:27.497322Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import requests, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:39:27.645252Z",
     "start_time": "2021-05-13T17:39:27.618978Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This function gets the csv from the url and places the new data in a dictionary with keys = ISIN,\n",
    "# and value = [NCB, ISSUER, MATURITY DATE, COUPON RATE]\n",
    "def downloadDataToDictionary(url,dictionary):\n",
    "    r = requests.get(url) # create HTTP response object\n",
    "    nameCompany = '' # make a string for the company name \n",
    "                     # (do this here so that is in scope of whole function)\n",
    "    if r.status_code != 200: return # if website wasn't accessed in the right way, \n",
    "                                    # stop the function\n",
    "    # this for loop loops through all the lines of the retrieved csv-file, except for the heading\n",
    "    for line in r.text.split('\\r\\n')[1:]:\n",
    "        if not re.search(r'[a-z]',line): continue # if the line doesn't contain letters, \n",
    "                                                  # go to the next line\n",
    "        if re.search(r',+$',line): line = re.sub(r',+$',r'',line) # remove commas at end of line\n",
    "        splitLine = line.split(',')\n",
    "        if len(splitLine) < 5: continue # We expect at least 5 items as we want 5 columns \n",
    "                                        # and name could lead to additional columns\n",
    "        if re.search(r'(?:\\\".*,.*\\\")',line): # searches commas between \" as these are part of the name \n",
    "                                             # and shouldn't be split\n",
    "            nameCompany = re.search(r'(?:\\\".*,.*\\\")',line).group(0) \n",
    "                                             # name of the company is between the \"\"\n",
    "            nameCompany = re.sub(r\"\\\"\",\"\",nameCompany) # remove the \"\"\n",
    "        else:\n",
    "            for str in splitLine:\n",
    "                re.sub('\\\"','',str)\n",
    "            nameCompany = splitLine[2]\n",
    "        if (splitLine[1] not in dictionary): # only add new ISINs to the dictionary\n",
    "            dictionary[splitLine[1]] = [splitLine[0], nameCompany, splitLine[-2], splitLine[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:39:54.467916Z",
     "start_time": "2021-05-13T17:39:27.648189Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dateToDownload = datetime.date(2017, 6, 23)\n",
    "change_url_date = datetime.date(2020, 3, 27)\n",
    "end_date = datetime.date(2021,4,23)\n",
    "delta = datetime.timedelta(days=7)\n",
    "dictionaryBondsECB = {}\n",
    "\n",
    "while dateToDownload <= change_url_date:\n",
    "    date = dateToDownload.strftime(\"%Y%m%d\")\n",
    "    url = \"https://www.ecb.europa.eu/mopo/pdf/CSPPholdings_\"+date+\".csv\"\n",
    "    downloadDataToDictionary(url,dictionaryBondsECB)\n",
    "    dateToDownload += delta\n",
    "dateToDownload+delta\n",
    "while dateToDownload <= end_date:\n",
    "    date = dateToDownload.strftime(\"%Y%m%d\")\n",
    "    url = \"https://www.ecb.europa.eu/mopo/pdf/CSPP_PEPP_corporate_bond_holdings_\"+date+\".csv\"\n",
    "    downloadDataToDictionary(url,dictionaryBondsECB)\n",
    "    dateToDownload += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:39:54.499726Z",
     "start_time": "2021-05-13T17:39:54.470861Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matrixData = [] # 2D array with row per ISIN and columns for different data\n",
    "for ISIN, dataInDictionary in dictionaryBondsECB.items():\n",
    "    item = [ISIN] + dataInDictionary\n",
    "    matrixData.append(item)\n",
    "holdingsECB = pd.DataFrame(matrixData, columns=[\"ISIN\",\"NCB\",\"ISSUER\",\"MATURITY DATE\",\"COUPON RATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:39:54.515682Z",
     "start_time": "2021-05-13T17:39:54.501720Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Export data to csv for easy retrieval on computers with Eikon\n",
    "holdingsECB.to_csv('data/holdingsECB.csv',index=False,sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ECB green bonds that are listed on Euronext stock exchange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:39:54.981332Z",
     "start_time": "2021-05-13T17:39:54.517678Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issuer</th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Listing Date</th>\n",
       "      <th>Amount (million)</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Bond Type</th>\n",
       "      <th>Listing Venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AB STENA METALL FINANS</td>\n",
       "      <td>NO0010823362</td>\n",
       "      <td>2018-09-03 00:00:00</td>\n",
       "      <td>800.0</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Green Bond</td>\n",
       "      <td>Oslo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABN AMRO BANK N.V.</td>\n",
       "      <td>XS1982037696</td>\n",
       "      <td>2019-04-15 00:00:00</td>\n",
       "      <td>750.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Green Bond</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABN AMRO BANK N.V.</td>\n",
       "      <td>XS1808739459</td>\n",
       "      <td>2018-04-18 00:00:00</td>\n",
       "      <td>750.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Green Bond</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABN AMRO BANK N.V.</td>\n",
       "      <td>XS1422841202</td>\n",
       "      <td>2016-05-31 00:00:00</td>\n",
       "      <td>500.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Green Bond</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACCIONA FINANCIACIÓN FILIALES, S.A. UNIPERSONAL</td>\n",
       "      <td>XS2327979675</td>\n",
       "      <td>2021-04-07 00:00:00</td>\n",
       "      <td>62.0</td>\n",
       "      <td>RON</td>\n",
       "      <td>Green Bond</td>\n",
       "      <td>Dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>VESTEDA FINANCE BV</td>\n",
       "      <td>XS2001183164</td>\n",
       "      <td>2019-05-24 00:00:00</td>\n",
       "      <td>500.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Green Bond</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>VILLE DE PARIS</td>\n",
       "      <td>FR00140007D0</td>\n",
       "      <td>2020-10-20 00:00:00</td>\n",
       "      <td>300.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Green Bond</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>VILLE DE PARIS</td>\n",
       "      <td>FR0013054897</td>\n",
       "      <td>2015-11-18 00:00:00</td>\n",
       "      <td>300.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Green Bond</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>VZ VENDOR FINANCING II B.V.</td>\n",
       "      <td>XS2272845798</td>\n",
       "      <td>2021-01-15 00:00:00</td>\n",
       "      <td>700.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Green Bond</td>\n",
       "      <td>Dublin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>WERELDHAVE BELGIUM</td>\n",
       "      <td>BE0002777580</td>\n",
       "      <td>2021-03-31 00:00:00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Green Bond</td>\n",
       "      <td>Brussels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Issuer          ISIN  \\\n",
       "0                             AB STENA METALL FINANS  NO0010823362   \n",
       "1                                 ABN AMRO BANK N.V.  XS1982037696   \n",
       "2                                 ABN AMRO BANK N.V.  XS1808739459   \n",
       "3                                 ABN AMRO BANK N.V.  XS1422841202   \n",
       "4    ACCIONA FINANCIACIÓN FILIALES, S.A. UNIPERSONAL  XS2327979675   \n",
       "..                                               ...           ...   \n",
       "432                               VESTEDA FINANCE BV  XS2001183164   \n",
       "433                                   VILLE DE PARIS  FR00140007D0   \n",
       "434                                   VILLE DE PARIS  FR0013054897   \n",
       "435                      VZ VENDOR FINANCING II B.V.  XS2272845798   \n",
       "436                               WERELDHAVE BELGIUM  BE0002777580   \n",
       "\n",
       "            Listing Date  Amount (million) Currency   Bond Type Listing Venue  \n",
       "0    2018-09-03 00:00:00             800.0      SEK  Green Bond          Oslo  \n",
       "1    2019-04-15 00:00:00             750.0      EUR  Green Bond     Amsterdam  \n",
       "2    2018-04-18 00:00:00             750.0      EUR  Green Bond     Amsterdam  \n",
       "3    2016-05-31 00:00:00             500.0      EUR  Green Bond     Amsterdam  \n",
       "4    2021-04-07 00:00:00              62.0      RON  Green Bond        Dublin  \n",
       "..                   ...               ...      ...         ...           ...  \n",
       "432  2019-05-24 00:00:00             500.0      EUR  Green Bond     Amsterdam  \n",
       "433  2020-10-20 00:00:00             300.0      EUR  Green Bond         Paris  \n",
       "434  2015-11-18 00:00:00             300.0      EUR  Green Bond         Paris  \n",
       "435  2021-01-15 00:00:00             700.0      EUR  Green Bond        Dublin  \n",
       "436  2021-03-31 00:00:00              32.0      EUR  Green Bond      Brussels  \n",
       "\n",
       "[437 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading data of green bonds listed on Euronext \n",
    "euronext_greenbonds = pd.read_excel(\"data/Euronext-Green-Bond-List.xlsx\", header=0)\n",
    "euronext_greenbonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:39:54.996292Z",
     "start_time": "2021-05-13T17:39:54.982330Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NO0010823362\n",
       "1      XS1982037696\n",
       "2      XS1808739459\n",
       "3      XS1422841202\n",
       "4      XS2327979675\n",
       "           ...     \n",
       "432    XS2001183164\n",
       "433    FR00140007D0\n",
       "434    FR0013054897\n",
       "435    XS2272845798\n",
       "436    BE0002777580\n",
       "Name: ISIN, Length: 437, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the ISIN of the Euronext green bonds \n",
    "euronext_greenbond_isin = euronext_greenbonds[\"ISIN\"]\n",
    "euronext_greenbond_isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:39:55.011929Z",
     "start_time": "2021-05-13T17:39:54.998288Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>NCB</th>\n",
       "      <th>ISSUER</th>\n",
       "      <th>MATURITY DATE</th>\n",
       "      <th>COUPON RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>XS1400167133</td>\n",
       "      <td>BE</td>\n",
       "      <td>Alliander N.V.</td>\n",
       "      <td>22/04/2026</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>XS1550149204</td>\n",
       "      <td>IT</td>\n",
       "      <td>ENEL Finance Intl N.V.</td>\n",
       "      <td>16/09/2024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>FR0013170834</td>\n",
       "      <td>FR</td>\n",
       "      <td>Fonciere des Regions S.A.</td>\n",
       "      <td>20/05/2026</td>\n",
       "      <td>1.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>XS1241581096</td>\n",
       "      <td>BE</td>\n",
       "      <td>TenneT Holding BV</td>\n",
       "      <td>04/06/2027</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>XS1241581179</td>\n",
       "      <td>BE</td>\n",
       "      <td>TenneT Holding BV</td>\n",
       "      <td>04/06/2021</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>XS2320453884</td>\n",
       "      <td>FI</td>\n",
       "      <td>UPM-Kymmene OYJ</td>\n",
       "      <td>22/03/2031</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>FR0013426731</td>\n",
       "      <td>FR</td>\n",
       "      <td>Regie Autonome des Transports Parisiens (RATP)</td>\n",
       "      <td>20/06/2029</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>XS2324772453</td>\n",
       "      <td>IT</td>\n",
       "      <td>Ferrovie dello Stato Ital.SpA</td>\n",
       "      <td>25/03/2028</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>FR0013447232</td>\n",
       "      <td>FR</td>\n",
       "      <td>Covivio S.A.</td>\n",
       "      <td>17/09/2031</td>\n",
       "      <td>1.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>XS2331315635</td>\n",
       "      <td>BE</td>\n",
       "      <td>ENEXIS Holding NV</td>\n",
       "      <td>14/04/2033</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISIN NCB                                          ISSUER  \\\n",
       "51    XS1400167133  BE                                  Alliander N.V.   \n",
       "289   XS1550149204  IT                          ENEL Finance Intl N.V.   \n",
       "338   FR0013170834  FR                       Fonciere des Regions S.A.   \n",
       "656   XS1241581096  BE                               TenneT Holding BV   \n",
       "657   XS1241581179  BE                               TenneT Holding BV   \n",
       "...            ...  ..                                             ...   \n",
       "1796  XS2320453884  FI                                 UPM-Kymmene OYJ   \n",
       "1813  FR0013426731  FR  Regie Autonome des Transports Parisiens (RATP)   \n",
       "1814  XS2324772453  IT                   Ferrovie dello Stato Ital.SpA   \n",
       "1818  FR0013447232  FR                                    Covivio S.A.   \n",
       "1819  XS2331315635  BE                               ENEXIS Holding NV   \n",
       "\n",
       "     MATURITY DATE COUPON RATE  \n",
       "51      22/04/2026       0.875  \n",
       "289     16/09/2024           1  \n",
       "338     20/05/2026       1.875  \n",
       "656     04/06/2027        1.75  \n",
       "657     04/06/2021       0.875  \n",
       "...            ...         ...  \n",
       "1796    22/03/2031         0.5  \n",
       "1813    20/06/2029        0.35  \n",
       "1814    25/03/2028       0.375  \n",
       "1818    17/09/2031       1.125  \n",
       "1819    14/04/2033       0.375  \n",
       "\n",
       "[65 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comparing the ISINs of the ECB and Euronext green bonds and returning matches \n",
    "ecbgreenbonds = holdingsECB[(holdingsECB[\"ISIN\"].isin(euronext_greenbond_isin))]\n",
    "ecbgreenbonds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Sector Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all sector data from PermID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:39:55.182680Z",
     "start_time": "2021-05-13T17:39:55.013924Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Requirements\n",
    "from OpenPermID import OpenPermID\n",
    "import Levenshtein\n",
    "import geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T17:39:55.198629Z",
     "start_time": "2021-05-13T17:39:55.184638Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Gain access to the permid database\n",
    "opid = OpenPermID()\n",
    "opid.set_access_token(\"r95vEAhvmucG8iNGtsP17hjbgUGMhz4j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.064Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "holdingsECB = pd.read_csv(\"data/holdingsECB.csv\", header=0, delimiter=';')\n",
    "companies = holdingsECB.ISSUER.astype('string').unique()\n",
    "permid_mappings = pd.DataFrame({})\n",
    "unmapped_companies = []\n",
    "\n",
    "for company in companies:\n",
    "    \n",
    "    # In case of connection error, allow it to try at most 5 times\n",
    "    err, count = 0, 0\n",
    "    while (err != None and count < 5):\n",
    "        output, err = opid.search(company)\n",
    "        count = count - 1\n",
    "    if err != None:\n",
    "        unmapped_companies.append(company)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    df = output['organizations']\n",
    "    if len(df) == 0:\n",
    "        permid = np.NaN\n",
    "        name = np.NaN\n",
    "    elif len(df) == 1:\n",
    "        permid = df.iloc[0,0].split('/')[-1]\n",
    "        name = df.iloc[0,1]\n",
    "    else:\n",
    "        # If multiple records are return, choose the record which the company name is the most similar to the keyword\n",
    "        similarityScores = df.organizationName.apply(lambda x: Levenshtein.ratio(company, x))\n",
    "        max_index = similarityScores.idxmax()\n",
    "        permid = df.iloc[max_index, 0].split('/')[-1]\n",
    "        name = df.iloc[max_index, 1]\n",
    "    permid_mappings = permid_mappings.append(pd.DataFrame({'keyword':[company], 'companyName': [name], 'PermID':[permid]}))\n",
    "    \n",
    "permid_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.066Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "permids = permid_mappings.PermID.dropna().astype('string')\n",
    "sector_lookups = pd.DataFrame({})\n",
    "unsuccessful_lookups = []\n",
    "\n",
    "for permid in permids:\n",
    "    \n",
    "    # In case of connection error, allow it to try at most 5 times\n",
    "    err, count = 0, 0\n",
    "    while (err != None and count < 5):\n",
    "        output, err = opid.lookup(permid)\n",
    "        count = count - 1\n",
    "    if err != None:\n",
    "        unsuccessful_lookups.append(permid)\n",
    "        continue\n",
    "\n",
    "    if \"hasPrimaryBusinessSector\" in output.columns:\n",
    "        sector_info = output.loc[:, 'hasPrimaryBusinessSector': 'hasPrimaryIndustryGroup']\n",
    "        sector_info = sector_info.applymap(lambda x: x.split('/')[-1])\n",
    "    if \"isIncorporatedIn\" in output.columns:\n",
    "        loc_info = output.loc[:, 'isIncorporatedIn': 'isDomiciledIn']\n",
    "        loc_info = loc_info.applymap(lambda x: x.split('/')[-2])\n",
    "        \n",
    "    row = pd.DataFrame({'PermID': [permid]})\n",
    "    row = pd.concat([row, sector_info], axis = 1) if type(sector_info) == pd.DataFrame else row\n",
    "    row = pd.concat([row, loc_info], axis = 1) if type(loc_info) == pd.DataFrame else row\n",
    "    sector_lookups = sector_lookups.append(row)\n",
    "    \n",
    "    sector_info, loc_info = None, None\n",
    "\n",
    "sector_lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.068Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sector_lookups_converted = sector_lookups.copy()\n",
    "sector_types = sector_lookups.columns[1:4]\n",
    "for sector_type in sector_types:\n",
    "    sector_dict = {}\n",
    "    sectors = sector_lookups.loc[:, sector_type].dropna().astype('string').unique()\n",
    "    for sector in sectors:\n",
    "        output, err = opid.lookup(sector)\n",
    "        sector_dict[sector] = output.iloc[0, -1]\n",
    "    sector_lookups_converted[sector_type] = sector_lookups[sector_type].fillna('missing').astype('string').apply(lambda x: np.NaN if x == 'missing' else sector_dict[x])\n",
    "\n",
    "loc_types = sector_lookups.columns[4:]\n",
    "for loc_type in loc_types:\n",
    "    loc_dict = {}\n",
    "    locs = sector_lookups.loc[:, loc_type].dropna().astype('string').unique()\n",
    "    for loc in locs:\n",
    "        g = geocoder.geonames(loc, method='details', key='brian1998716')\n",
    "        loc_dict[loc] = g.address\n",
    "    sector_lookups_converted[loc_type] = sector_lookups[loc_type].fillna('missing').astype('string').apply(lambda x: np.NaN if x == 'missing' else loc_dict[x])\n",
    "\n",
    "sector_lookups_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.071Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sector_mappings = pd.merge(permid_mappings, sector_lookups_converted, how = 'left', on = 'PermID')\n",
    "sector_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.073Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sector_mappings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Represent industries and sectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pie chart to represent the number of times an industry, sector or supersector is present in the data (multiple bonds for the same company are counted separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.076Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # TODO: add to requirements if used\n",
    "\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        if (pct > 2.4):\n",
    "            return '{p:.2f}%'.format(p=pct)\n",
    "        else:\n",
    "            return ''\n",
    "    return my_autopct\n",
    "\n",
    "def get_all_sectors(sector_type):\n",
    "    sector_mappings['number']=1 # TODO: count them in a cleaner way\n",
    "    sectors = sector_mappings[[sector_type, 'number']].groupby([sector_type]).sum()\n",
    "    sectors = sectors.sort_values(\"number\", axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)\n",
    "    return sectors\n",
    "    \n",
    "def make_pie_chart(column_name):\n",
    "    fig = plt.figure(figsize=(9,9))\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    sectors = get_all_sectors(column_name)\n",
    "    \n",
    "    sectors.plot(kind='pie', y='number', ax=ax, autopct=make_autopct(sectors['number']), fontsize=12, legend=False, rotatelabels=True, pctdistance=0.8)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(column_name+\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.078Z"
    }
   },
   "outputs": [],
   "source": [
    "make_pie_chart('hasPrimaryBusinessSector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.080Z"
    }
   },
   "outputs": [],
   "source": [
    "make_pie_chart('hasPrimaryEconomicSector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.082Z"
    }
   },
   "outputs": [],
   "source": [
    "# make_pie_chart('hasPrimaryIndustryGroup') # TODO: fix error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which industries and sectors are green?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the emission data on sectors in the European Union."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.085Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data from kaggle: https://www.kaggle.com/cathetorres/ghg-emissions-by-country-and-economic-sector\n",
    "historical_emissions = pd.read_csv(\"data/Sector_data/historical_emissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.087Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter out all the sectors from the EU for which kaggle has emission data\n",
    "historical_emissions_EU = historical_emissions[historical_emissions[\"Country\"]== \"European Union (27)\"]\n",
    "\n",
    "def get_all_sectors_EU(sector_type): #TODO: make function one with previous\n",
    "    historical_emissions_EU[\"number\"]=1 # TODO: count them in a cleaner way\n",
    "    sectors_EU = historical_emissions_EU[[sector_type, \"number\"]].groupby([sector_type]).sum()\n",
    "    sectors_EU = sectors_EU.sort_values(\"number\", axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)\n",
    "    return sectors_EU\n",
    "\n",
    "all_sectors_EU = get_all_sectors_EU(\"Sector\")\n",
    "print(all_sectors_EU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map these sectors with the ones in which ECB invested\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.090Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set perfect matches: TODO work with regex or text analysis?\n",
    "primary_business_sector = get_all_sectors(\"hasPrimaryBusinessSector\")\n",
    "primary_business_sector[\"EU_Sector_Name\"] = \"Other\" # Default sector is \"Other\"\n",
    "for i in range(0, primary_business_sector.shape[0]):\n",
    "        if primary_business_sector.index[i] in all_sectors_EU.index:\n",
    "            primary_business_sector[\"EU_Sector_Name\"][i]=primary_business_sector.index[i]\n",
    "            \n",
    "# Manually append list, those in comments will get the sector \"Other\"\n",
    "\n",
    "# primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Banking & Investment Services\"]=\"\"\n",
    "# primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Utilities\"]=\"\"\n",
    "primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Real Estate\"]=\"Building\"\n",
    "primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Industrial & Commercial Services\"]=\"Industrial Processes and Product Use\" # Or \"Industrial Processes\"\n",
    "# primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Investment Holding Companies\"]=\"\"\n",
    "primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Chemicals\"]=\"Fugitive Emissions\" # TODO: Is this true?\n",
    "# primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Insurance\"]=\"\"\n",
    "primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Energy - Fossil Fuels\"]=\"Total fossil fuels and cement\"\n",
    "#primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Telecommunications Services\"]=\"\"\n",
    "primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Automobiles & Auto Parts\"]=\"Manufacturing/Construction\" # TODO: Is this true?\n",
    "primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Industrial Goods\"]=\"Industrial Processes and Product Use\" # Or \"Industrial Processes\"\n",
    "primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Technology Equipment\"]=\"Manufacturing/Construction\" # TODO: Is this true?\n",
    "#primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Cyclical Consumer Services\"]=\"\"\n",
    "#primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Cyclical Consumer Products\"]=\"\"\n",
    "#primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Food & Beverages\"]=\"test\" # Agriculture?\n",
    "#primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Mineral Resources\"]=\"\"\n",
    "#primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Pharmaceuticals & Medical Research\"]=\"\"\n",
    "#primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Applied Resources\"]=\"\"\n",
    "#primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Healthcare Services & Equipment\"]=\"\"\n",
    "#primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Food & Drug Retailing\"]=\"\"\n",
    "#primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Software & IT Services\"]=\"\"\n",
    "#primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Retailers\"]=\"\"\n",
    "#primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Collective Investments\"]=\"\"\n",
    "primary_business_sector[\"EU_Sector_Name\"][primary_business_sector.index == \"Consumer Goods Conglomerates\"]=\"Industrial Processes and Product Use\"\n",
    "primary_business_sector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: analyse the emission known for every sector and decide on a threshold to call some of them green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: find a way to calculate which percentage is green and conlude whether this is more than random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all the Eikon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.094Z"
    }
   },
   "outputs": [],
   "source": [
    "eikon_data_folder = \"data/\"\n",
    "eikon_data_environment = pd.read_csv(eikon_data_folder+\"holdingsECBEnvironment.txt\",sep=\"\\t\")\n",
    "# TODO: remove right, empty columns from data frame\n",
    "eikon_data_general = pd.read_csv(eikon_data_folder+\"holdingsECBGeneralInfo.txt\",sep=\"\\t\")\n",
    "eikon_data_industry = pd.read_csv(eikon_data_folder+\"holdingsECBIndustryAndSector.txt\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.096Z"
    }
   },
   "outputs": [],
   "source": [
    "eikon_data_merged = eikon_data_general.merge(eikon_data_environment, \"left\", \"ISIN\") #append environment\n",
    "eikon_data_complete = eikon_data_merged.merge(eikon_data_industry, \"left\", \"ISIN\") # appended industry\n",
    "eikon_data_complete.rename(columns={'CO2.1': 'CO2_1'}, inplace=True) #changed column name to prevent syntax errors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read all data from eligible universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.098Z"
    }
   },
   "outputs": [],
   "source": [
    "eligible_environment = pd.read_csv(eikon_data_folder+\"eligibleUniverseEnvironment.txt\",sep=\"\\t\")\n",
    "eligible_general = pd.read_csv(eikon_data_folder+\"eligibleUniverseGeneralInfo.txt\",sep=\"\\t\")\n",
    "eligible_industry = pd.read_csv(eikon_data_folder+\"eligibleUniverseIndustryAndSector.txt\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.101Z"
    }
   },
   "outputs": [],
   "source": [
    "eligible_complete = eligible_general.merge(eligible_environment, \"left\", \"ISIN\").merge(eligible_industry, \"left\", \"ISIN\")\n",
    "eligible_complete.rename(columns={\"Issuer\": \"ISSUER\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare how many bonds from the eligible universe the ECB bought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.103Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overlap = eikon_data_complete[(eikon_data_complete[\"ISIN\"].isin(eligible_complete[\"ISIN\"]))]\n",
    "print(\"the percentage of bonds bought by ECB in eligible universe that we have info on:    \", \n",
    "      overlap.shape[0]/eligible_complete.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Eikon and PermID databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.105Z"
    }
   },
   "outputs": [],
   "source": [
    "NaN_message = \"Unable to collect data for the field(.*)\"\n",
    "sector_data = eikon_data_complete[['ISIN', 'NCB', 'ISSUER','ICB Industry name','ICB Sector name','ICB Supersector name']]\n",
    "sector_data = sector_data.replace(to_replace = NaN_message, value = np.NaN, regex = True)\n",
    "\n",
    "sector_data_company = pd.DataFrame({})\n",
    "for i in sector_data.ISSUER.unique():\n",
    "    df = sector_data[sector_data.ISSUER == i].iloc[[0]].reset_index()\n",
    "    index = df.notnull().sum(axis = 1).idxmax()\n",
    "    sector_data_company = sector_data_company.append(df.iloc[[index]])\n",
    "sector_data_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.107Z"
    }
   },
   "outputs": [],
   "source": [
    "sector_data_company.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.109Z"
    }
   },
   "outputs": [],
   "source": [
    "sector_mappings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__More companies mapped in Eikon database (370 vs 339), but more industries mapped in PermID database (313 vs 158).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry and sector analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all industries and sectors in which ECB invested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.113Z"
    }
   },
   "outputs": [],
   "source": [
    "sector_data = eikon_data_complete[['ISIN','ICB Industry name','ICB Sector name','ICB Supersector name']]\n",
    "sector_data = sector_data[sector_data['ICB Industry name'] != \"Unable to collect data for the field 'TR.ICBIndustry' and some specific identifier(s).\"]\n",
    "# TODO: use regex to make it less stringent\n",
    "# sector_data.to_excel('output/test_sector_data.xlsx') # Export the resulting data to an excel file, create output folder if you want to use it!\n",
    "percentage_known_sectors = len(sector_data.index)/len(eikon_data_complete.index) # 50% of the rows removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Represent industries and sectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a pie chart to represent the number of times an industry, sector or supersector is present in the data (multiple bonds for the same company are counted separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.115Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # TODO: add to requirements if used\n",
    "\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        if (pct > 2.4):\n",
    "            return '{p:.2f}%'.format(p=pct)\n",
    "        else:\n",
    "            return ''\n",
    "    return my_autopct\n",
    "\n",
    "def get_all_sectors(sector_type):\n",
    "    sector_data['number']=1 # TODO: count them in a cleaner way\n",
    "    sectors = sector_data[[sector_type, 'number']].groupby([sector_type]).sum()\n",
    "    sectors = sectors.sort_values(\"number\", axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)\n",
    "    return sectors\n",
    "    \n",
    "def make_pie_chart(column_name):\n",
    "    fig = plt.figure(figsize=(9,9))\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    sectors = get_all_sectors(column_name)\n",
    "    \n",
    "    sectors.plot(kind='pie', y='number', ax=ax, autopct=make_autopct(sectors['number']), fontsize=12, legend=False, rotatelabels=True, pctdistance=0.8)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(column_name+\"\\n\\n\\n\")\n",
    "\n",
    "make_pie_chart('ICB Supersector name')\n",
    "make_pie_chart('ICB Sector name')\n",
    "make_pie_chart('ICB Industry name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T18:14:25.820905Z",
     "start_time": "2021-05-03T18:14:25.802394Z"
    }
   },
   "source": [
    "## Which industries and sectors are green?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: automate this process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sector is considered green if it is in the list of \"Green economy sectors\" by Igor Mishevski.\n",
    "https://medium.com/@mishevski/green-economy-sectors-ceecabeec7f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.119Z"
    }
   },
   "outputs": [],
   "source": [
    "industries = get_all_sectors('ICB Industry name')\n",
    "super_sectors = get_all_sectors('ICB Supersector name')\n",
    "sectors = get_all_sectors('ICB Sector name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.121Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_green_sectors = [\"Real Estate\", \"Energy\", \"Oil, Gas and Coal\"] # Buildings, Energy supply, ... TODO: update list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.125Z"
    }
   },
   "outputs": [],
   "source": [
    "industries[\"green\"]=0\n",
    "super_sectors[\"green\"]=0\n",
    "sectors[\"green\"]=0\n",
    "for i in range(0, len(industries.index)):\n",
    "    if industries.index[i] in list_of_green_sectors:\n",
    "        industries[\"green\"][i]=1\n",
    "    if super_sectors.index[i] in list_of_green_sectors:\n",
    "        super_sectors[\"green\"][i]=1\n",
    "    if sectors.index[i] in list_of_green_sectors:\n",
    "        sectors[\"green\"][i]=1\n",
    "print(industries)\n",
    "print(super_sectors)\n",
    "print(sectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.128Z"
    }
   },
   "outputs": [],
   "source": [
    " def show_table(column_names, row_names, content):\n",
    "    fig, ax = plt.subplots() \n",
    "    ax.set_axis_off() \n",
    "    table = ax.table( \n",
    "        cellText = content,  \n",
    "        rowLabels = row_names,  \n",
    "        colLabels = column_names, \n",
    "        rowColours =[\"c\"] * len(row_names),  \n",
    "        colColours =[\"c\"] * len(column_names), \n",
    "        cellLoc ='center',  \n",
    "        loc ='upper left')         \n",
    "\n",
    "    ax.set_title('Percentage of industries or sectors that is green', \n",
    "                 fontweight =\"bold\") \n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the percentage of represented industries considered green\n",
    "percentage_industries_green = industries[\"green\"].sum()/len(industries.index)\n",
    "percentage_super_sectors_green = super_sectors[\"green\"].sum()/len(super_sectors.index)\n",
    "percentage_sectors_green = sectors[\"green\"].sum()/len(sectors.index)\n",
    "\n",
    "# Calculate the percentage of represented bonds in green industries\n",
    "percentage_bonds_green_industries = (industries[\"green\"]*industries[\"number\"]).sum()/industries[\"number\"].sum()\n",
    "percentage_bonds_green_super_sectors = (super_sectors[\"green\"]*super_sectors[\"number\"]).sum()/super_sectors[\"number\"].sum()\n",
    "percentage_bonds_green_sectors = (sectors[\"green\"]*sectors[\"number\"]).sum()/sectors[\"number\"].sum()\n",
    "\n",
    "show_table([\"Compared to number of sectors\", \"Compared to number of bonds\"], [\"Industries\", \"Super sectors\", \"Sectors\"],\n",
    "           [[percentage_industries_green.round(3), percentage_bonds_green_industries.round(3)],\n",
    "            [percentage_super_sectors_green.round(3), percentage_bonds_green_super_sectors.round(3)],\n",
    "            [percentage_sectors_green.round(3), percentage_bonds_green_sectors.round(3)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CO2 Data/Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Spaghetti plot CO$_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.134Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "co2_data = eikon_data_complete[[\"ISSUER\", \"CO2\", \"CO2_1\"]] #compnay name and CO2 subset \n",
    "company_co2_data = co2_data.drop_duplicates(subset= [\"ISSUER\"]) #Unique company name subset \n",
    "company_co2_data = company_co2_data[(company_co2_data.CO2 != '0') & (company_co2_data.CO2_1 != '0')] #not null value for CO2\n",
    "company_co2_data = company_co2_data.reset_index() #resets index\n",
    "company_co2_data = company_co2_data.drop(columns=[\"index\"]) #removes extra column\n",
    "company_co2_data = company_co2_data.replace(to_replace = '[,]', value ='.', regex=True) #making decimal points legible\n",
    "company_co2_data['CO2'] =company_co2_data['CO2'].astype(float) #converting numbers to floats \n",
    "company_co2_data['CO2_1'] =company_co2_data['CO2_1'].astype(float)\n",
    "\n",
    "#overall slope increase or decrease \n",
    "slopes = company_co2_data['CO2_1'] - company_co2_data['CO2']\n",
    "slopes.sum() #shows an overall decrease in total emissions **Could cluster by sector. Hard to do anything else with 2 data points*\n",
    "\n",
    "\n",
    "#making data easier to graph \n",
    "co2graph_data = company_co2_data[[\"CO2\", \"CO2_1\"]]\n",
    "co2graph_data = co2graph_data.transpose()\n",
    "co2graph_data.insert(0, \"x\", [0, 1], True)\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "palette = plt.get_cmap('Set1')\n",
    "\n",
    "#spaghetti plot of CO2 emissions \n",
    "plt.figure(figsize=(20,20))\n",
    "for column in co2graph_data.drop(columns=[\"x\"], axis=1):\n",
    "    plt.plot(co2graph_data[\"x\"], co2graph_data[column], marker='', linewidth=1, alpha=0.9)\n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Histogram change in CO$_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.136Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(x=slopes, bins=7,alpha=0.7)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(r'Histogram of the change in nomalized CO$_2$ emission during the CSPP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### emission of 2021 as a function of the emission in 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.139Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(company_co2_data[\"CO2\"],company_co2_data[\"CO2_1\"],'o')\n",
    "plt.title(\"emission of 2021 as a function of the emission in 2015\", size=15)\n",
    "plt.xlabel(\"emission in 2015\", size=15)\n",
    "plt.ylabel(\"emission in 2021\",size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make a linear fit through for this graph (see github of course: data analytics > radient_descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.142Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# We will use the module Linear Regression of sklearn to perform the analysis\n",
    "# Initialize the model\n",
    "ols = LinearRegression()\n",
    "# Fit the model to the data\n",
    "ols.fit(company_co2_data[\"CO2\"].values.reshape(-1, 1),company_co2_data[\"CO2_1\"])\n",
    "\n",
    "print('Fit is of the form:',np.round(ols.intercept_,3),'+',np.round(ols.coef_[0],3),'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As the slope is slightly below one, we can conclude that in general, the normalized CO$_2$ emission decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.145Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# plot of data\n",
    "plt.plot(company_co2_data[\"CO2\"],company_co2_data[\"CO2_1\"],'o',label=\"data\")\n",
    "\n",
    "# plot of fit\n",
    "x = np.arange(0,max((company_co2_data[\"CO2\"])+100))\n",
    "y = ols.intercept_ + ols.coef_[0]*x\n",
    "plt.plot(x,y,'r-',label=\"fit\")\n",
    "\n",
    "# making a nice figure\n",
    "plt.title(\"emission of 2021 as a function of the emission in 2015\", size=15)\n",
    "plt.xlabel(\"emission in 2015\", size=15)\n",
    "plt.ylabel(\"emission in 2021\",size=15)\n",
    "plt.legend(fontsize=\"15\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESG data/plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for cleaning the ESG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.148Z"
    }
   },
   "outputs": [],
   "source": [
    "def cleaning_esg_data(df):\n",
    "    column_names_esg_company_data = [\"ISSUER\", \"ESG Score 2015\", \"ESG Score 2016\", \"ESG Score 2017\", \n",
    "                                \"ESG Score 2018\", \"ESG Score 2019\", \"ESG Score 2020\", \n",
    "                                \"ESG Score 2021\"]\n",
    "    #started cleaning data as above \n",
    "    esg_data = df[column_names_esg_company_data]\n",
    "    esg_company_data = esg_data.drop_duplicates(subset= [\"ISSUER\"])\n",
    "    esg_company_data = esg_company_data.replace(to_replace = '[,]', value ='.', regex=True)\n",
    "\n",
    "    # replace zeros with nans, as these are easier to replace\n",
    "    esg_company_data = esg_company_data.replace(to_replace = '0', value = np.nan) \n",
    "\n",
    "    # remove rows with no data for ESG score\n",
    "    esg_company_data.dropna(axis=0, how='all', \n",
    "                            subset=column_names_esg_company_data[1:8], inplace=True)\n",
    "\n",
    "    #converting all numbers to floats \n",
    "    for column_name in column_names_esg_company_data[1:8]:\n",
    "        esg_company_data[column_name] = esg_company_data[column_name].astype(float)\n",
    "\n",
    "    # interpolate data that is missing\n",
    "    esg_company_data.iloc[:,1:] = esg_company_data.iloc[:,1:].interpolate(method='linear', axis=1, limit_direction='both',\n",
    "                                                                          inplace=False)\n",
    "    #TODO: If we want to keep this apart, we can make a new variable holding the filled in dataframe\n",
    "\n",
    "    # reset the indexes\n",
    "    esg_company_data = esg_company_data.reset_index()\n",
    "    esg_company_data = esg_company_data.drop(columns=[\"index\"])\n",
    "    \n",
    "    return esg_company_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.152Z"
    }
   },
   "outputs": [],
   "source": [
    "esg_company_data_holdings = cleaning_esg_data(eikon_data_complete)\n",
    "esg_company_data_eligible = cleaning_esg_data(eligible_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spaghetti plot ESG Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.155Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "years = range(2015,2022)\n",
    "for index,row in esg_company_data_holdings.iterrows():\n",
    "    plt.plot(years,row[1:8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.157Z"
    }
   },
   "outputs": [],
   "source": [
    "esg_company_data_holdings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.160Z"
    }
   },
   "outputs": [],
   "source": [
    "esg_company_data_eligible.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.162Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "years = range(2015,2022)\n",
    "\n",
    "mean_holdings = esg_company_data_holdings.mean().values\n",
    "error_holdings = esg_company_data_holdings.std().values\n",
    "\n",
    "mean_eligible = esg_company_data_eligible.mean().values\n",
    "error_eligible = esg_company_data_eligible.std().values\n",
    "\n",
    "plt.errorbar(years, mean_holdings, yerr=error_holdings, ecolor='r', capsize=10, label=\"holdings\")\n",
    "\n",
    "plt.errorbar(years, mean_eligible, yerr=error_eligible, ecolor='y', capsize=10, label=\"eligible\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this figure, we can clearly see that the average ESG-score of the companies increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.165Z"
    }
   },
   "outputs": [],
   "source": [
    "esg_company_data_holdings.iloc[:,1:].boxplot(figsize=(10,10),color='y')\n",
    "esg_company_data_eligible.iloc[:,1:].boxplot(figsize=(10,10),color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESG evolution of each company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit the evolution of each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.168Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def linReg_esg_company_data(esg_company_data):\n",
    "    list_of_coef = []\n",
    "    list_of_intercepts = []\n",
    "    years = np.arange(0,7)\n",
    "    # We will use the module Linear Regression of sklearn to perform the analysis\n",
    "    # Initialize the model\n",
    "    ols = LinearRegression()\n",
    "    # Fit the model to the data\n",
    "    for index,row in esg_company_data.iterrows():\n",
    "        resultOfFit = ols.fit(years.reshape(-1, 1),row[1:8])\n",
    "        list_of_coef.append(resultOfFit.coef_[0])\n",
    "        list_of_intercepts.append(resultOfFit.intercept_)\n",
    "    return list_of_coef,list_of_intercepts\n",
    "\n",
    "list_of_coef_holdings, list_of_intercepts_holdings = linReg_esg_company_data(esg_company_data_holdings)\n",
    "list_of_coef_eligible, list_of_intercepts_eligible = linReg_esg_company_data(esg_company_data_eligible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a boxplot of the coefficients of these fits. This should give an indication about the general evolution (increase vs decrease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.170Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.boxplot([list_of_coef_holdings, list_of_coef_eligible], \"y\")\n",
    "plt.xticks(ticks=[1,2], labels=[\"holdings\", \"eligible\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure shows us that only roughly 25% of companies have a negative slope, while the other 75% have an increasin ESG score.\n",
    "\n",
    "Let us now try to find a relation between the initial ESG score and the most recent one. This can be done by plotting and calculating the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.172Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(list_of_intercepts_holdings,list_of_coef_holdings, 'b.')\n",
    "plt.plot(list_of_intercepts_eligible,list_of_coef_eligible, 'y.')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-13T17:39:16.174Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"holdings:\\n\", np.corrcoef(list_of_coef_holdings, list_of_intercepts_holdings),\n",
    "      \"\\n eligible:\\n\", np.corrcoef(list_of_coef_eligible, list_of_intercepts_eligible))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some negative correlation ==> lower initial value, faster increase in ESG score."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "c66e68dc8effbb73dddbef0493505d10f36de5f905f8b8ed3ac14ee9c27e255b"
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 277.4,
   "position": {
    "height": "299.4px",
    "left": "971.4px",
    "right": "20px",
    "top": "98px",
    "width": "493px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
