{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T08:17:33.018798Z",
     "start_time": "2021-05-01T08:17:21.812318Z"
    }
   },
   "outputs": [],
   "source": [
    "# List of modules that are not installed in the course\n",
    "!pip install OpenPermID\n",
    "!pip install Levenshtein\n",
    "!pip install geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T09:29:10.229751Z",
     "start_time": "2021-05-01T09:29:08.413052Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading all bonds ever owned in CSPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T09:29:20.698518Z",
     "start_time": "2021-05-01T09:29:20.372499Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T09:29:21.740466Z",
     "start_time": "2021-05-01T09:29:21.730493Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function gets the csv from the url and places the new data in a dictionary with keys = ISIN,\n",
    "# and value = [NCB, ISSUER, MATURITY DATE, COUPON RATE]\n",
    "def downloadDataToDictionary(url,dictionary):\n",
    "    r = requests.get(url) # create HTTP response object\n",
    "    nameCompany = '' # make a string for the company name \n",
    "                     # (do this here so that is in scope of whole function)\n",
    "    if r.status_code != 200: return # if website wasn't accessed in the right way, \n",
    "                                    # stop the function\n",
    "    # this for loop loops through all the lines of the retrieved csv-file, except for the heading\n",
    "    for line in r.text.split('\\r\\n')[1:]:\n",
    "        if not re.search(r'[a-z]',line): continue # if the line doesn't contain letters, \n",
    "                                                  # go to the next line\n",
    "        if re.search(r',+$',line): line = re.sub(r',+$',r'',line) # remove commas at end of line\n",
    "        splitLine = line.split(',')\n",
    "        if len(splitLine) < 5: continue # We expect at least 5 items as we want 5 columns \n",
    "                                        # and name could lead to additional columns\n",
    "        if re.search(r'(?:\\\".*,.*\\\")',line): # searches commas between \" as these are part of the name \n",
    "                                             # and shouldn't be split\n",
    "            nameCompany = re.search(r'(?:\\\".*,.*\\\")',line).group(0) \n",
    "                                             # name of the company is between the \"\"\n",
    "            nameCompany = re.sub(r\"\\\"\",\"\",nameCompany) # remove the \"\"\n",
    "        else:\n",
    "            for str in splitLine:\n",
    "                re.sub('\\\"','',str)\n",
    "            nameCompany = splitLine[2]\n",
    "        if (splitLine[1] not in dictionary): # only add new ISINs to the dictionary\n",
    "            dictionary[splitLine[1]] = [splitLine[0], nameCompany, splitLine[-2], splitLine[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T09:29:52.222926Z",
     "start_time": "2021-05-01T09:29:24.835549Z"
    }
   },
   "outputs": [],
   "source": [
    "dateToDownload = datetime.date(2017, 6, 23)\n",
    "change_url_date = datetime.date(2020, 3, 27)\n",
    "end_date = datetime.date(2021,4,23)\n",
    "delta = datetime.timedelta(days=7)\n",
    "dictionaryBondsECB = {}\n",
    "\n",
    "while dateToDownload <= change_url_date:\n",
    "    date = dateToDownload.strftime(\"%Y%m%d\")\n",
    "    url = \"https://www.ecb.europa.eu/mopo/pdf/CSPPholdings_\"+date+\".csv\"\n",
    "    downloadDataToDictionary(url,dictionaryBondsECB)\n",
    "    dateToDownload += delta\n",
    "dateToDownload+delta\n",
    "while dateToDownload <= end_date:\n",
    "    date = dateToDownload.strftime(\"%Y%m%d\")\n",
    "    url = \"https://www.ecb.europa.eu/mopo/pdf/CSPP_PEPP_corporate_bond_holdings_\"+date+\".csv\"\n",
    "    downloadDataToDictionary(url,dictionaryBondsECB)\n",
    "    dateToDownload += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T09:29:52.366208Z",
     "start_time": "2021-05-01T09:29:52.349211Z"
    }
   },
   "outputs": [],
   "source": [
    "matrixData = [] # 2D array with row per ISIN and columns for different data\n",
    "for ISIN, dataInDictionary in dictionaryBondsECB.items():\n",
    "    item = [ISIN] + dataInDictionary\n",
    "    matrixData.append(item)\n",
    "holdingsECB = pd.DataFrame(matrixData, columns=[\"ISIN\",\"NCB\",\"ISSUER\",\"MATURITY DATE\",\"COUPON RATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T08:18:09.472250Z",
     "start_time": "2021-05-01T08:18:09.403378Z"
    }
   },
   "outputs": [],
   "source": [
    "# Export data to csv for easy retrieval on computers with Eikon\n",
    "holdingsECB.to_csv('data/holdingsECB.csv',index=False,sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECB green bonds that are listed on Euronext stock exchange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T08:18:09.923111Z",
     "start_time": "2021-05-01T08:18:09.486212Z"
    }
   },
   "outputs": [],
   "source": [
    "#reading data of green bonds listed on Euronext \n",
    "euronext_greenbonds = pd.read_excel(\"data/Euronext-Green-Bond-List.xlsx\", header=0)\n",
    "euronext_greenbonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T08:18:09.938067Z",
     "start_time": "2021-05-01T08:18:09.927096Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Getting the ISIN of the Euronext green bonds \n",
    "euronext_greenbond_isin = euronext_greenbonds[\"ISIN\"]\n",
    "euronext_greenbond_isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T08:18:09.985937Z",
     "start_time": "2021-05-01T08:18:09.942056Z"
    }
   },
   "outputs": [],
   "source": [
    "#Comparing the ISINs of the ECB and Euronext green bonds and returning matches \n",
    "ecbgreenbonds = holdingsECB[(holdingsECB[\"ISIN\"].isin(euronext_greenbond_isin))]\n",
    "ecbgreenbonds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Sectors and Locations of Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T08:20:43.212587Z",
     "start_time": "2021-05-01T08:20:43.208598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Requirements\n",
    "from OpenPermID import OpenPermID\n",
    "import Levenshtein\n",
    "import geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T08:20:44.799670Z",
     "start_time": "2021-05-01T08:20:44.795681Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gain access to the permid database\n",
    "opid = OpenPermID()\n",
    "opid.set_access_token(\"r95vEAhvmucG8iNGtsP17hjbgUGMhz4j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T08:28:05.461497Z",
     "start_time": "2021-05-01T08:24:34.385943Z"
    }
   },
   "outputs": [],
   "source": [
    "holdings20210402 = pd.read_csv(\"data/CSPP_PEPP_corporate_bond_holdings_20210402.csv\", header=0, encoding='latin-1') #TODO: remove!\n",
    "companies = holdings20210402.ISSUER.astype('string').unique()\n",
    "permid_mappings = pd.DataFrame({})\n",
    "unmapped_companies = []\n",
    "\n",
    "for company in companies:\n",
    "    \n",
    "    # In case of connection error, allow it to try at most 5 times\n",
    "    err, count = 0, 0\n",
    "    while (err != None and count < 5):\n",
    "        output, err = opid.search(company)\n",
    "    if err != None:\n",
    "        unmapped_companies.append(company)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    df = output['organizations']\n",
    "    if len(df) == 0:\n",
    "        permid = np.NaN\n",
    "        name = np.NaN\n",
    "    elif len(df) == 1:\n",
    "        permid = df.iloc[0,0].split('/')[-1]\n",
    "        name = df.iloc[0,1]\n",
    "    else:\n",
    "        # If multiple records are return, choose the record which the company name is the most similar to the keyword\n",
    "        similarityScores = df.organizationName.apply(lambda x: Levenshtein.ratio(company, x))\n",
    "        max_index = similarityScores.idxmax()\n",
    "        permid = df.iloc[max_index, 0].split('/')[-1]\n",
    "        name = df.iloc[max_index, 1]\n",
    "    permid_mappings = permid_mappings.append(pd.DataFrame({'keyword':[company], 'companyName': [name], 'PermID':[permid]}))\n",
    "    \n",
    "permid_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T08:31:18.193093Z",
     "start_time": "2021-05-01T08:28:05.578187Z"
    }
   },
   "outputs": [],
   "source": [
    "permids = permid_mappings.PermID.dropna().astype('string')\n",
    "sector_lookups = pd.DataFrame({})\n",
    "unsuccessful_lookups = []\n",
    "\n",
    "for permid in permids:\n",
    "    \n",
    "    # In case of connection error, allow it to try at most 5 times\n",
    "    err, count = 0, 0\n",
    "    while (err != None and count < 5):\n",
    "        output, err = opid.lookup(permid)\n",
    "    if err != None:\n",
    "        unsuccessful_lookups.append(permid)\n",
    "        continue\n",
    "\n",
    "    if \"hasPrimaryBusinessSector\" in output.columns:\n",
    "        sector_info = output.loc[:, 'hasPrimaryBusinessSector': 'hasPrimaryIndustryGroup']\n",
    "        sector_info = sector_info.applymap(lambda x: x.split('/')[-1])\n",
    "    if \"isIncorporatedIn\" in output.columns:\n",
    "        loc_info = output.loc[:, 'isIncorporatedIn': 'isDomiciledIn']\n",
    "        loc_info = loc_info.applymap(lambda x: x.split('/')[-2])\n",
    "        \n",
    "    row = pd.DataFrame({'PermID': [permid]})\n",
    "    row = pd.concat([row, sector_info], axis = 1) if type(sector_info) == pd.DataFrame else row\n",
    "    row = pd.concat([row, loc_info], axis = 1) if type(loc_info) == pd.DataFrame else row\n",
    "    sector_lookups = sector_lookups.append(row)\n",
    "    \n",
    "    sector_info, loc_info = None, None\n",
    "\n",
    "sector_lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T08:31:18.197065Z",
     "start_time": "2021-05-01T08:20:51.716Z"
    }
   },
   "outputs": [],
   "source": [
    "sector_lookups_converted = sector_lookups.copy()\n",
    "sector_types = sector_lookups.columns[1:4]\n",
    "for sector_type in sector_types:\n",
    "    sector_dict = {}\n",
    "    sectors = sector_lookups.loc[:, sector_type].dropna().astype('string').unique()\n",
    "    for sector in sectors:\n",
    "        output, err = opid.lookup(sector)\n",
    "        sector_dict[sector] = output.iloc[0, -1]\n",
    "    sector_lookups_converted[sector_type] = sector_lookups[sector_type].fillna('missing').astype('string').apply(lambda x: np.NaN if x == 'missing' else sector_dict[x])\n",
    "\n",
    "loc_types = sector_lookups.columns[4:]\n",
    "for loc_type in loc_types:\n",
    "    loc_dict = {}\n",
    "    locs = sector_lookups.loc[:, loc_type].dropna().astype('string').unique()\n",
    "    for loc in locs:\n",
    "        g = geocoder.geonames(loc, method='details', key='brian1998716')\n",
    "        loc_dict[loc] = g.address\n",
    "    sector_lookups_converted[loc_type] = sector_lookups[loc_type].fillna('missing').astype('string').apply(lambda x: np.NaN if x == 'missing' else loc_dict[x])\n",
    "\n",
    "sector_lookups_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T08:31:18.201055Z",
     "start_time": "2021-05-01T08:20:53.158Z"
    }
   },
   "outputs": [],
   "source": [
    "sector_mappings = pd.merge(permid_mappings, sector_lookups_converted, how = 'left', on = 'PermID')\n",
    "sector_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T08:31:18.204047Z",
     "start_time": "2021-05-01T08:20:54.807Z"
    }
   },
   "outputs": [],
   "source": [
    "sector_mappings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all the Eikon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T09:35:09.983483Z",
     "start_time": "2021-05-01T09:35:09.956514Z"
    }
   },
   "outputs": [],
   "source": [
    "eikon_data_folder = \"data/\"\n",
    "eikon_data_environment = pd.read_csv(eikon_data_folder+\"holdingsECBEnvironment.txt\",sep=\"\\t\")\n",
    "# TODO: remove right, empty columns from data frame\n",
    "eikon_data_general = pd.read_csv(eikon_data_folder+\"holdingsECBGeneralInfo.txt\",sep=\"\\t\")\n",
    "eikon_data_industry = pd.read_csv(eikon_data_folder+\"holdingsECBIndustryAndSector.txt\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T09:35:11.496196Z",
     "start_time": "2021-05-01T09:35:11.477287Z"
    }
   },
   "outputs": [],
   "source": [
    "eikon_data_merged = holdingsECB.merge(eikon_data_environment, \"left\", \"ISIN\") # ECB with environment appended\n",
    "eikon_data_merged = eikon_data_merged.merge(eikon_data_general, \"left\", \"ISIN\") # appended general\n",
    "eikon_data_complete = eikon_data_merged.merge(eikon_data_industry, \"left\", \"ISIN\") # appended industry\n",
    "eikon_data_complete.rename(columns={'CO2.1': 'CO2_1'}, inplace=True) #changed column name to prevent syntax errors \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all industries in which ECB invested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Import all the data into one big data frame (done)\n",
    "2) Search for all the ISINs\n",
    "3) Find \"green bond\", \"ESG bond\" and most importantly \"sector\"\n",
    "4) Analyse sectoer ?! --> TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T09:35:13.859288Z",
     "start_time": "2021-05-01T09:35:13.851310Z"
    }
   },
   "outputs": [],
   "source": [
    "sector_data = eikon_data_complete[['ISIN','ICB Industry name','ICB Sector name','ICB Supersector name']]\n",
    "sector_data = sector_data[sector_data['ICB Industry name'] != \"Unable to collect data for the field 'TR.ICBIndustry' and some specific identifier(s).\"]\n",
    "# TODO: use regex to make it less stringent\n",
    "# sector_data.to_excel('output/test_sector_data.xlsx') # Export the resulting data to an excel file, create output folder if you want to use it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pie chart to represent the number of times an industry, sector or supersector is present in the data (multiple bonds for the same company are counted separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T09:35:17.248150Z",
     "start_time": "2021-05-01T09:35:15.984440Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # TODO: add to requirements if used\n",
    "\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        if (pct > 2.4):\n",
    "            return '{p:.2f}%'.format(p=pct)\n",
    "        else:\n",
    "            return ''\n",
    "    return my_autopct\n",
    "\n",
    "def make_pie_chart(column_name):\n",
    "    fig = plt.figure(figsize=(9,9))\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    sector_data['number']=1\n",
    "    sectors = sector_data[[column_name, 'number']].groupby([column_name]).sum()\n",
    "    sectors = sectors.sort_values(\"number\", axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)\n",
    "\n",
    "    sectors.plot(kind='pie', y='number', ax=ax, autopct=make_autopct(sectors['number']), fontsize=12, legend=False, rotatelabels=True, pctdistance=0.8)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(column_name+\"\\n\\n\\n\")\n",
    "\n",
    "make_pie_chart('ICB Supersector name')\n",
    "make_pie_chart('ICB Sector name')\n",
    "make_pie_chart('ICB Industry name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ##CO2 and ESG Data/Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "co2_data = eikon_data_complete[[\"ISSUER_x\", \"CO2\", \"CO2_1\"]] #compnay name and CO2 subset \n",
    "company_co2_data = co2_data.drop_duplicates(subset= [\"ISSUER_x\"]) #Unique company name subset \n",
    "company_co2_data = company_co2_data[(company_co2_data.CO2 != '0') & (company_co2_data.CO2_1 != '0')] #not null value for CO2\n",
    "company_co2_data = company_co2_data.reset_index() #resets index\n",
    "company_co2_data = company_co2_data.drop(columns=[\"index\"]) #removes extra column\n",
    "company_co2_data = company_co2_data.replace(to_replace = '[,]', value ='.', regex=True) #making decimal points legible\n",
    "company_co2_data['CO2'] =company_co2_data['CO2'].astype(float) #converting numbers to floats \n",
    "company_co2_data['CO2_1'] =company_co2_data['CO2_1'].astype(float)\n",
    "\n",
    "#overall slope increase or decrease \n",
    "slopes = company_co2_data['CO2_1'] - company_co2_data['CO2']\n",
    "slopes.sum() #shows an overall decrease in total emissions **Could cluster by sector. Hard to do anything else with 2 data points*\n",
    "\n",
    "\n",
    "#making data easier to graph \n",
    "co2graph_data = company_co2_data[[\"CO2\", \"CO2_1\"]]\n",
    "co2graph_data = co2graph_data.transpose()\n",
    "co2graph_data.insert(0, \"x\", [0, 1], True)\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "palette = plt.get_cmap('Set1')\n",
    "\n",
    "#spaghetti plot of CO2 emissions \n",
    "plt.figure(figsize=(20,20))\n",
    "for column in co2graph_data.drop(columns=[\"x\"], axis=1):\n",
    "    plt.plot(co2graph_data[\"x\"], co2graph_data[column], marker='', linewidth=1, alpha=0.9)\n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#started cleaning data as above \n",
    "esg_data = eikon_data_complete[[\"ISSUER_x\", \"ESG Score 2015\", \"ESG Score 2016\", \"ESG Score 2017\", \"ESG Score 2018\", \"ESG Score 2019\", \"ESG Score 2020\", \"ESG Score 2021\"]]\n",
    "esg_company_data = esg_data.drop_duplicates(subset= [\"ISSUER_x\"])\n",
    "esg_company_data = esg_company_data.reset_index()\n",
    "esg_company_data = esg_company_data.drop(columns=[\"index\"])\n",
    "esg_company_data = esg_company_data.replace(to_replace = '[,]', value ='.', regex=True)\n",
    "esg_company_data = esg_company_data.replace(to_replace = \"NaN\", value = '0') #not sure why this doesnt work \n",
    "\n",
    "#converting all numbers to floats \n",
    "esg_company_data['ESG Score 2015'] = esg_company_data['ESG Score 2015'].astype(float)\n",
    "esg_company_data['ESG Score 2016'] = esg_company_data['ESG Score 2016'].astype(float)\n",
    "esg_company_data['ESG Score 2017'] = esg_company_data['ESG Score 2017'].astype(float)\n",
    "esg_company_data['ESG Score 2018'] = esg_company_data['ESG Score 2018'].astype(float)\n",
    "esg_company_data['ESG Score 2019'] = esg_company_data['ESG Score 2019'].astype(float)\n",
    "esg_company_data['ESG Score 2020'] = esg_company_data['ESG Score 2020'].astype(float)\n",
    "esg_company_data['ESG Score 2021'] = esg_company_data['ESG Score 2021'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "c66e68dc8effbb73dddbef0493505d10f36de5f905f8b8ed3ac14ee9c27e255b"
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
